{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c2747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code learn ranking based on fairness def of CTR, and evaluate based on fairness def of CTR with trust bias (Compass)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from YahooDataReader import YahooDataReader\n",
    "import math\n",
    "import statistics\n",
    "import itertools\n",
    "from random import seed, shuffle\n",
    "import os,sys\n",
    "import urllib.request  as urllib2\n",
    "from collections import defaultdict\n",
    "from sklearn import preprocessing\n",
    "from IPython.display import display\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad20f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compas\n",
    "\n",
    "SEED = 1234\n",
    "seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def add_intercept(x):\n",
    "\n",
    "    \"\"\" Add intercept to the data before linear classification \"\"\"\n",
    "    m,n = x.shape\n",
    "    intercept = np.ones(m).reshape(m, 1) # the constant b\n",
    "    return np.concatenate((intercept, x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36f6e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_compas_data():\n",
    "\n",
    "    FEATURES_CLASSIFICATION = [\"age_cat\", \"race\", \"sex\", \"priors_count\", \"c_charge_degree\"] #features to be used for classification\n",
    "    CONT_VARIABLES = [\"priors_count\"] # continuous features, will need to be handled separately from categorical features, categorical features will be encoded using one-hot\n",
    "    CLASS_FEATURE = \"two_year_recid\" # the decision variable\n",
    "    SENSITIVE_ATTRS = [\"race\"]\n",
    "\n",
    "\n",
    "    COMPAS_INPUT_FILE = \"../data/compas.csv\"\n",
    "    #check_data_file(COMPAS_INPUT_FILE)\n",
    "\n",
    "    # load the data and get some stats\n",
    "    df = pd.read_csv(COMPAS_INPUT_FILE)\n",
    "    df\n",
    "    df = df.dropna(subset=[\"days_b_screening_arrest\"]) # dropping missing vals\n",
    "\n",
    "    # convert to np array\n",
    "    data = df.to_dict('list')\n",
    "    for k in data.keys():\n",
    "        data[k] = np.array(data[k])\n",
    "\n",
    "\n",
    "    \"\"\" Filtering the data \"\"\"\n",
    "\n",
    "    # These filters are the same as propublica (refer to https://github.com/propublica/compas-analysis)\n",
    "    # If the charge date of a defendants Compas scored crime was not within 30 days from when the person was arrested, we assume that because of data quality reasons, that we do not have the right offense. \n",
    "    idx = np.logical_and(data[\"days_b_screening_arrest\"]<=30, data[\"days_b_screening_arrest\"]>=-30)\n",
    "\n",
    "\n",
    "    # We coded the recidivist flag -- is_recid -- to be -1 if we could not find a compas case at all.\n",
    "    idx = np.logical_and(idx, data[\"is_recid\"] != -1)\n",
    "\n",
    "    # In a similar vein, ordinary traffic offenses -- those with a c_charge_degree of 'O' -- will not result in Jail time are removed (only two of them).\n",
    "    idx = np.logical_and(idx, data[\"c_charge_degree\"] != \"O\") # F: felony, M: misconduct\n",
    "\n",
    "    # We filtered the underlying data from Broward county to include only those rows representing people who had either recidivated in two years, or had at least two years outside of a correctional facility.\n",
    "    idx = np.logical_and(idx, data[\"score_text\"] != \"NA\")\n",
    "\n",
    "    # we will only consider blacks and whites for this analysis\n",
    "    idx = np.logical_and(idx, np.logical_or(data[\"race\"] == \"African-American\", data[\"race\"] == \"Caucasian\"))\n",
    "\n",
    "    # select the examples that satisfy this criteria\n",
    "    for k in data.keys():\n",
    "        data[k] = data[k][idx]\n",
    "\n",
    "    #display(data)\n",
    "\n",
    "    \"\"\" Feature normalization and one hot encoding \"\"\"\n",
    "\n",
    "    # convert class label 0 to -1\n",
    "    y = data[CLASS_FEATURE]\n",
    "    #y[y==0] = -1\n",
    "\n",
    "\n",
    "\n",
    "    print (\"\\nNumber of people recidivating within two years\")\n",
    "    print (pd.Series(y).value_counts())\n",
    "    print (\"\\n\")\n",
    "\n",
    "\n",
    "    X = np.array([]).reshape(len(y), 0) # empty array with num rows same as num examples, will hstack the features to it\n",
    "    x_control = defaultdict(list)\n",
    "\n",
    "    feature_names = []\n",
    "    for attr in FEATURES_CLASSIFICATION:\n",
    "        print (\"attr\", attr)\n",
    "        vals = data[attr]\n",
    "        if attr in CONT_VARIABLES:\n",
    "            vals = [float(v) for v in vals]\n",
    "            vals = preprocessing.scale(vals) # 0 mean and 1 variance  \n",
    "            vals = np.reshape(vals, (len(y), -1)) # convert from 1-d arr to a 2-d arr with one col\n",
    "\n",
    "        else: # for binary categorical variables, the label binarizer uses just one var instead of two\n",
    "            lb = preprocessing.LabelBinarizer()\n",
    "            lb.fit(vals)\n",
    "            vals = lb.transform(vals)\n",
    "    \n",
    "        # add to sensitive features dict\n",
    "        if attr in SENSITIVE_ATTRS:\n",
    "            print (\"True\")\n",
    "            x_control[attr] = vals\n",
    "\n",
    "\n",
    "        # add to learnable features\n",
    "        X = np.hstack((X, vals))\n",
    "\n",
    "        if attr in CONT_VARIABLES: # continuous feature, just append the name\n",
    "            feature_names.append(attr)\n",
    "        else: # categorical features\n",
    "            if vals.shape[1] == 1: # binary features that passed through lib binarizer\n",
    "                feature_names.append(attr + \"_\" + str(lb.classes_[1]))\n",
    "            else:\n",
    "                for k in lb.classes_: # non-binary categorical features, need to add the names for each cat\n",
    "                    feature_names.append(attr + \"_\" + str(k))\n",
    "\n",
    "    print (\"feature_names\", feature_names)\n",
    "    # convert the sensitive feature to 1-d array\n",
    "    x_control = dict(x_control)\n",
    "    for k in x_control.keys():\n",
    "        assert(x_control[k].shape[1] == 1) # make sure that the sensitive feature is binary after one hot encoding\n",
    "        x_control[k] = np.array(x_control[k]).flatten()\n",
    "    print (\"x_control\", x_control)\n",
    "    # sys.exit(1)\n",
    "\n",
    "    #\"\"\"permute the date randomly\"\"\"\n",
    "    #perm = list(range(0,X.shape[0])\n",
    "    #shuffle(perm)\n",
    "    #X = X[perm]\n",
    "    #y = y[perm]\n",
    "    #for k in x_control.keys():\n",
    "    #x_control[k] = x_control[k][perm]\n",
    "\n",
    "\n",
    "    X = add_intercept(X)\n",
    "\n",
    "    feature_names = [\"intercept\"] + feature_names\n",
    "    assert(len(feature_names) == X.shape[1])\n",
    "    print (\"Features we will be using for classification are:\", feature_names, \"\\n\")\n",
    "\n",
    "    # wrtie data in csv file\n",
    "\n",
    "    #A = pd.DataFrame(list(x_control.items()),columns=['index','race'])\n",
    "    #A.to_csv('compas_A.csv', sep='\\t') \n",
    "    y = pd.DataFrame(data=y,columns=['two_year_recid'])\n",
    "    y.to_csv('compas_Y.csv', sep='\\t') \n",
    "    X1 = pd.DataFrame(data=X[0:,0:],columns=feature_names) #X[0,1:] #index=X[0:,0]\n",
    "    #print (\"X1B\", X1.keys())\n",
    "    A = X1.race_Caucasian\n",
    "    #print (\"A\", A)\n",
    "    X1.drop(['race_Caucasian'], axis=1) #in place-- does not work.So X1 is unchanged\n",
    "    print (\"X1\", X1.keys())\n",
    "    #X = pd.DataFrame(list(X.items()),columns=feature_names)\n",
    "    X1.to_csv('compas_X.csv', sep='\\t')\n",
    "    A.to_csv('compas_A.csv', sep='\\t')\n",
    "    data = pd.concat([A,X1],axis = 1).values #race_caucasian column is added to ll data. So this feature appears twice, once at index=0 and also at index=5. Here, we consider cocuasians to be bottom rank in criminal search\n",
    "    #print (\"data\", data)\n",
    "    return data, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaa0c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sample_record(orig_data, orig_label):\n",
    "\n",
    "    #data, to_protect, label = load_compas_data() #read_arrhythmia(shuffle=True, dropmissing=True)\n",
    "\n",
    "    data = orig_data\n",
    "    orig_label = np.array(orig_label)\n",
    "    label = orig_label\n",
    "\n",
    "    data = pd.DataFrame(data)\n",
    "    label = pd.DataFrame(label)\n",
    "    display(data)\n",
    "\n",
    "\n",
    "    Y = np.array(label)\n",
    "    Y = np.squeeze(Y)\n",
    "\n",
    "    #data = pd.concat([to_protect,data],axis = 1).values\n",
    "\n",
    "    X = np.array(data)\n",
    "\n",
    "    num_feats = X.shape[1]\n",
    "    numX = X.shape[0]\n",
    "\n",
    "\n",
    "    datasize = 500\n",
    "    cs_size = 25\n",
    "    split_on_doc = 0.8\n",
    "    testsize = 100\n",
    "    ratio_relevant = 0.4\n",
    "    ratios_col = Y * ratio_relevant + (1-Y)*(1-ratio_relevant)\n",
    "\n",
    "    # generate a candidate set of size 10 everytime\n",
    "    data_X = []\n",
    "    data_Y = []\n",
    "    test_X = []\n",
    "    test_Y = []\n",
    "    group_identities_train = []\n",
    "    group_identities_test = []\n",
    "    print(\"Sampling between 0 and {} for train\".format(numX*split_on_doc))\n",
    "    p = ratios_col[0:int(numX*split_on_doc)]\n",
    "    p = p / sum(p)\n",
    "    for i in range(datasize):\n",
    "        cs_indices = np.random.choice(np.arange(0, int(numX*split_on_doc), dtype=int), size=cs_size, p=p)\n",
    "        cs_X = X[cs_indices]\n",
    "        cs_Y = Y[cs_indices]\n",
    "        data_X.append(cs_X)\n",
    "        data_Y.append(cs_Y)\n",
    "        group_identities_train.append(cs_X[:,0]) #index=0 shows caucasian= whites\n",
    "    print(\"Sampling between {} and {} for test\".format(int(numX*split_on_doc), numX))\n",
    "    p = ratios_col[int(numX*split_on_doc):]\n",
    "    p = p/sum(p)\n",
    "    docID_test= []\n",
    "    while len(docID_test) < testsize: #used while instead of for to make sure given \"continue\", we still have len(testsize) qid#\n",
    "        cs_indices = np.random.choice(np.arange(numX*split_on_doc, numX, dtype=int), size=cs_size, p=p)\n",
    "        print (\"cs_indices\",cs_indices)\n",
    "        #*START: added to skip the sets that has zero female or male or all female rel score 0 or all male relscore 0*#\n",
    "        group_id= X[cs_indices,0]\n",
    "        print (\"group_id\", group_id)\n",
    "        if (len(set(group_id))==1 or \n",
    "            sum([Y[item] for i, item in enumerate(cs_indices) if group_id[i]==0]) == 0 or\n",
    "            sum([Y[item] for i, item in enumerate(cs_indices) if group_id[i]==1]) == 0):\n",
    "            #print (\"continue\")\n",
    "            continue\n",
    "        #*END: added to skip the sets that has zero female or male*#\n",
    "        docID_test.append (cs_indices.tolist())\n",
    "        print (\"docID_test\", docID_test)\n",
    "        test_X.append(X[cs_indices])\n",
    "        test_Y.append(Y[cs_indices])\n",
    "        group_identities_test.append(X[cs_indices,0])\n",
    "    \n",
    "\n",
    "    return data_X, data_Y, test_X, test_Y, docID_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39afbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data\n",
    "\n",
    "data, label = load_compas_data()\n",
    "#permuted_indices = np.random.permutation(len(data)) #permuted_data\n",
    "data_X, data_Y, test_X, test_Y, docID_test= make_sample_record(data, label)\n",
    "pkl.dump((data_X, data_Y), open(\"compas_train_rank_25.pkl\", \"wb\"))\n",
    "pkl.dump((test_X, test_Y), open(\"compas_test_rank_25.pkl\", \"wb\"))\n",
    "pickle.dump(docID_test, open( \"compas_docID_test_25.txt\", \"wb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bce1d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(data)\n",
    "MaleID= data_df[data_df[0]==1].index\n",
    "FemaleID= data_df[data_df[0]==0].index\n",
    "MaleID_str=[]\n",
    "FemaleID_str=[]\n",
    "for i in MaleID:\n",
    "    MaleID_str.append(str(i))\n",
    "for i in FemaleID:\n",
    "    FemaleID_str.append(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59d6297",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "\n",
    "docID_test = pickle.load( open( \"compas_docID_test_25.txt\", \"rb\" ) )\n",
    "\n",
    "with open('compas_train_rank_25.pkl', 'rb') as f:\n",
    "    data_train = pickle.load(f)\n",
    "\n",
    "with open('compas_test_rank_25.pkl', 'rb') as f:\n",
    "     data_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b652ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learn rel-scores\n",
    "\n",
    "dr = YahooDataReader(None)\n",
    "dr.data = pkl.load(open(\"compas_train_rank_25.pkl\", \"rb\"))\n",
    "vdr = YahooDataReader(None)\n",
    "vdr.data = pkl.load(open(\"compas_test_rank_25.pkl\",\"rb\"))                  \n",
    "model = linear_model.LinearRegression(fit_intercept=False, normalize=False)\n",
    "feats, rel = dr.data\n",
    "feats = np.array([item for sublist in feats for item in sublist])\n",
    "rel = np.array([item for sublist in rel for item in sublist])\n",
    "model.fit(feats, rel)\n",
    "# predictions on validation\n",
    "feats, rel = vdr.data\n",
    "se_sum = 0\n",
    "length = 0\n",
    "predicted_rels = []\n",
    "for i, query in enumerate(feats):\n",
    "    rel_pred = model.predict(query)\n",
    "\n",
    "            \n",
    "    predicted_rels.append(rel_pred)\n",
    "    se_sum += np.sum((rel_pred - rel[i])**2)\n",
    "    length += len(rel[i])\n",
    "#print (type(predicted_rels)) #predicted_rels has 100 subarray, each with 25 rel scores#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae16ec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code learn ranking based on fairness def of CTR, and evaluate based on fairness def of CTR with trust bias (German Credit)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "df = pd.read_csv(\"../data/german_credit_data.csv\", index_col=0)\n",
    "df = df.fillna(value=\"NA\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47315cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MaleID= df.query('Sex == \"male\"').index\n",
    "FemaleID= df.query('Sex == \"female\"').index\n",
    "MaleID_str=[]\n",
    "FemaleID_str=[]\n",
    "\n",
    "for i in MaleID:\n",
    "    MaleID_str.append(str(i))\n",
    "for i in FemaleID:\n",
    "    FemaleID_str.append(str(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ea47b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write data\n",
    "\n",
    "preprocess = make_column_transformer((StandardScaler(),['Age', 'Credit amount', 'Duration']),\n",
    "    (OneHotEncoder(sparse=False), ['Sex', 'Job', 'Housing', 'Saving accounts', 'Checking account', 'Purpose', 'Risk']))\n",
    "print (\"type\",type(df))\n",
    "mat = preprocess.fit_transform(df)\n",
    "mat[996, :]   #row 10 all columns (11th row in df)#\n",
    "\n",
    "\n",
    "X = mat[:, :-2]   #all rows of mat, without last two columns. X is an array containg 1000 subarray each with 29 elements#\n",
    "Y = mat[:, -1]  #all rows of mat, only last column. Y is an array contating 1000 element#\n",
    "num_feats = X.shape[1]\n",
    "# print (num_feats)\n",
    "numX = X.shape[0]\n",
    "# print (numX)\n",
    "\n",
    "datasize = 500 #number of qid in train\n",
    "cs_size = 25 #number of docs under each qid\n",
    "split_on_doc = 0.8\n",
    "testsize = 100 #number of qid in test\n",
    "ratio_relevant = 0.4\n",
    "ratios_col = Y * ratio_relevant + (1-Y)*(1-ratio_relevant)\n",
    "# print (ratios_col)\n",
    "\n",
    "# generate a candidate set of size 25 everytime for each qid\n",
    "data_X = []\n",
    "data_Y = []\n",
    "test_X = []\n",
    "test_Y = []\n",
    "group_identities_train = []\n",
    "group_identities_test = []\n",
    "print(\"Sampling between 0 and {} for train\".format(numX*split_on_doc))\n",
    "p = ratios_col[0:int(numX*split_on_doc)]\n",
    "p = p / sum(p)\n",
    "docID_train= [] #list of docID that was randomly chosen for each qid in train#\n",
    "for i in range(datasize):\n",
    "    cs_indices = np.random.choice(np.arange(0, numX*split_on_doc, dtype=int), size=cs_size, p=p) #doc index chosen for a qid#\n",
    "    #print (\"cs_indices\", cs_indices)\n",
    "    docID_train.append (cs_indices.tolist())\n",
    "    cs_X = X[cs_indices] #features of chosen docs#\n",
    "    cs_Y = Y[cs_indices] #rel of chosen docs#\n",
    "    data_X.append(cs_X)\n",
    "    data_Y.append(cs_Y)\n",
    "    #print (\"cs_X\", cs_X)\n",
    "    group_identities_train.append(cs_X[:,4]) #5th column (index=4) and all row. It is male column#\n",
    "    #print (\"group_identities_train\", group_identities_train)\n",
    "\n",
    "print(\"Sampling between {} and {} for test\".format(numX*split_on_doc, numX))\n",
    "p = ratios_col[int(numX*split_on_doc):]\n",
    "p = p/sum(p)\n",
    "docID_test= []\n",
    "#for i in range(testsize): \n",
    "while len(docID_test) < testsize: #used while instead of for to make sure given \"continue\", we still have len(testsize) docs#\n",
    "    cs_indices = np.random.choice(np.arange(numX*split_on_doc, numX, dtype=int), size=cs_size, p=p)\n",
    "    group_id= X[cs_indices,4]\n",
    "    if (len(set(group_id))==1 or \n",
    "        sum([Y[item] for i, item in enumerate(cs_indices) if group_id[i]==0]) == 0 or\n",
    "        sum([Y[item] for i, item in enumerate(cs_indices) if group_id[i]==1]) == 0):\n",
    "        continue\n",
    "    docID_test.append (cs_indices.tolist())\n",
    "    test_X.append(X[cs_indices])\n",
    "    test_Y.append(Y[cs_indices])\n",
    "    group_identities_test.append(X[cs_indices,4])\n",
    "\n",
    "\n",
    "\n",
    "pickle.dump(docID_test, open( \"german_docID_test_25.txt\", \"wb\" ) )\n",
    "\n",
    "pkl.dump((data_X, data_Y), open(\"german_train_rank_25.pkl\", \"wb\"))\n",
    "pkl.dump((test_X, test_Y), open(\"german_test_rank_25.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b96cc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "\n",
    "docID_test = pickle.load( open( \"german_docID_test_25.txt\", \"rb\" ) )\n",
    "\n",
    "with open('german_train_rank_25.pkl', 'rb') as f:\n",
    "    data_train = pickle.load(f)\n",
    "\n",
    "\n",
    "#same for data_test but with size 100 instead of 500\n",
    "with open('german_test_rank_25.pkl', 'rb') as f:\n",
    "     data_test = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757a9602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learn rel-scores\n",
    "\n",
    "dr = YahooDataReader(None)\n",
    "dr.data = pkl.load(open(\"german_train_rank_25.pkl\", \"rb\"))\n",
    "vdr = YahooDataReader(None)\n",
    "vdr.data = pkl.load(open(\"german_test_rank_25.pkl\",\"rb\"))                  \n",
    "model = linear_model.LinearRegression(fit_intercept=False, normalize=False)\n",
    "feats, rel = dr.data\n",
    "feats = np.array([item for sublist in feats for item in sublist])\n",
    "rel = np.array([item for sublist in rel for item in sublist])\n",
    "model.fit(feats, rel)\n",
    "# predictions on validation\n",
    "feats, rel = vdr.data\n",
    "se_sum = 0\n",
    "length = 0\n",
    "predicted_rels = []\n",
    "for i, query in enumerate(feats):\n",
    "    rel_pred = model.predict(query)\n",
    "    #print (rel_pred)\n",
    "    predicted_rels.append(rel_pred)\n",
    "    se_sum += np.sum((rel_pred - rel[i])**2)\n",
    "    length += len(rel[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890c8f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code learn ranking based on fairness def of CTR, and evaluate based on fairness def of CTR with trust bias (MovieLense)\n",
    "#Filter data to drop users and items with low number of interactions#\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import pickle as pkl\n",
    "import pickle\n",
    "\n",
    "def write_data(path, data):\n",
    "    f = open(path, 'w')\n",
    "    jsObj = json.dumps(data)\n",
    "    f.write(jsObj)\n",
    "    f.close()\n",
    "\n",
    "def dataset_filtering(interaction, core):\n",
    "    # filtering the dataset with core\n",
    "    # movielens is filtered by only remaining only users with at least 20 interactions\n",
    "    # we further filter the dataset by remaining users and items with at least 20 interactions\n",
    "    user_id_dic = {}  # record the number of interaction for each user and item\n",
    "    item_id_dic = {}\n",
    "    for (user_id, item_id) in interaction:\n",
    "        try:\n",
    "            user_id_dic[user_id] += 1\n",
    "        except:\n",
    "            user_id_dic[user_id] = 1\n",
    "        try:\n",
    "            item_id_dic[item_id] += 1\n",
    "        except:\n",
    "            item_id_dic[item_id] = 1\n",
    "    print ('#Original dataset')\n",
    "    print('  User:', len(user_id_dic), 'Item:', len(item_id_dic))\n",
    "    print('  User:', len(user_id_dic), 'Item:', len(item_id_dic), 'Interaction:', len(interaction), 'Sparsity:',\n",
    "          100 - len(interaction) * 100.0 / len(user_id_dic) / len(item_id_dic), '%')\n",
    "    sort_user = []\n",
    "    sort_item = []\n",
    "    for user_id in user_id_dic:\n",
    "        sort_user.append((user_id, user_id_dic[user_id]))\n",
    "    for item_id in item_id_dic:\n",
    "        sort_item.append((item_id, item_id_dic[item_id]))\n",
    "    sort_user.sort(key=lambda x: x[1])\n",
    "    sort_item.sort(key=lambda x: x[1])\n",
    "    print ('Fitering(core = ', core, '...', end = '')\n",
    "    while sort_user[0][1] < core or sort_item[0][1] < core:\n",
    "        # find out all users and items with less than core recorders\n",
    "        user_LessThanCore = set()\n",
    "        item_LessThanCore = set()\n",
    "        for pair in sort_user:\n",
    "            if pair[1] < core:\n",
    "                user_LessThanCore.add(pair[0])\n",
    "            else:\n",
    "                break\n",
    "        for pair in sort_item:\n",
    "            if pair[1] < core:\n",
    "                item_LessThanCore.add(pair[0])\n",
    "            else:\n",
    "                break\n",
    "        # reconstruct the interaction record, remove the cool one\n",
    "        interaction_filtered = []\n",
    "        for (user_id, item_id) in interaction:\n",
    "            if not (user_id in user_LessThanCore or item_id in item_LessThanCore):\n",
    "                interaction_filtered.append((user_id, item_id))\n",
    "        # update the record\n",
    "        interaction = interaction_filtered\n",
    "\n",
    "        # count the number of each user and item in new data, check if all cool users and items are removed\n",
    "        # reset all memory variables\n",
    "        user_id_dic = {}  # record the number of interaction for each user and item\n",
    "        item_id_dic = {}\n",
    "        for (user_id, item_id) in interaction:\n",
    "            try:\n",
    "                user_id_dic[user_id] += 1\n",
    "            except:\n",
    "                user_id_dic[user_id] = 1\n",
    "            try:\n",
    "                item_id_dic[item_id] += 1\n",
    "            except:\n",
    "                item_id_dic[item_id] = 1\n",
    "\n",
    "        sort_user = []\n",
    "        sort_item = []\n",
    "        for user_id in user_id_dic:\n",
    "            sort_user.append((user_id, user_id_dic[user_id]))\n",
    "        for item_id in item_id_dic:\n",
    "            sort_item.append((item_id, item_id_dic[item_id]))\n",
    "        sort_user.sort(key=lambda x: x[1])\n",
    "        sort_item.sort(key=lambda x: x[1])\n",
    "        print (len(interaction), end = ' ')\n",
    "    print()\n",
    "    print ('#Filtered dataset')\n",
    "    print ('  User:', len(user_id_dic), 'Item:', len(item_id_dic), 'Interaction:', len(interaction), 'Sparsity:', 100 - len(interaction) * 100.0 / len(user_id_dic) / len(item_id_dic), '%')\n",
    "    return interaction\n",
    "\n",
    "\n",
    "\n",
    "#read interaction data\n",
    "core = 80\n",
    "cold_thre = 15\n",
    "\n",
    "\n",
    "\n",
    "path_read_inter = '../../../MovieLense/ml-100k/u.data'\n",
    "f_inter = open(path_read_inter, \"r\")\n",
    "data_inter = f_inter.read()\n",
    "f_inter.close()\n",
    "Interaction = []\n",
    "\n",
    "data_inter = data_inter.split('\\n')\n",
    "#print (data_inter)\n",
    "for interactions in data_inter:\n",
    "    #interactions = interactions.split('::')\n",
    "    interactions = interactions.split('\\t')\n",
    "    #print (\"interaction\", interactions)\n",
    "    if len(interactions) > 1:\n",
    "        Interaction.append((interactions[0], interactions[1]))\n",
    "#Interaction = list(set(Interaction))\n",
    "\n",
    "#print(\"1\", len(Interaction))\n",
    "Interaction = dataset_filtering(Interaction, core)\n",
    "#print (\"2\", len(Interaction))\n",
    "\n",
    "\n",
    "remained_items=[]\n",
    "for el in range(len(Interaction)):\n",
    "    remained_items.append(Interaction[el][1])\n",
    "#print (set(remained_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ce40cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find less popular movies\n",
    "\n",
    "dataset = pd.read_csv('../../../MovieLense/ml-100k/u.data', sep='\\t')\n",
    "dataset.head()\n",
    "\n",
    "movieDic={}\n",
    "movie_list=[]\n",
    "\n",
    "\n",
    "for i in range(len(Interaction)):    ##if want to decide the least popular after pruning cold users/items\n",
    "    movie_list.append(Interaction[i][1])\n",
    "#print (len(set(movie_list)))\n",
    "\n",
    "res = Counter(movie_list)\n",
    "# print (res)\n",
    "\n",
    "least_rated= res.most_common()[-70:]\n",
    "least_rated_movies=[]\n",
    "for i in range(len(least_rated)):\n",
    "    least_rated_movies.append((str(least_rated[i][0])))\n",
    "# print (least_rated_movies)\n",
    "FemaleID_str= least_rated_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4d7af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write data\n",
    "\n",
    "#processs interaction data\n",
    "user_list= []\n",
    "item_list= []\n",
    "for i in range(len(Interaction)):\n",
    "    user_list.append(int(Interaction[i][0]))\n",
    "    item_list.append(int(Interaction[i][1]))\n",
    "user_set= sorted(set(user_list))\n",
    "item_set= sorted(set(item_list))\n",
    "#print (\"user_set\",user_set)\n",
    "#print (\"item_set\",item_set)\n",
    "\n",
    "D={} #dictionaey with key=user and value=items that user interacted with\n",
    "D = defaultdict(list)\n",
    "for j in range(len(Interaction)):\n",
    "    D[int(Interaction[j][0])].append(int(Interaction[j][1]))\n",
    "#print (len(D))\n",
    "\n",
    "#process user data and item data (dropped zipcode as it cannot be either scaler or onehotencoding)\n",
    "data_user= pd.read_csv('../../../MovieLense/ml-100k/u.user', sep='|', \n",
    "                  names=[\"user_id\", \"age\", \"gender\", \"job\",\"zipcode\"])\n",
    "data_user= data_user.drop(columns=['zipcode'])\n",
    "print (\"data_user\", data_user)\n",
    "\n",
    "data_item= pd.read_csv('../../../MovieLense/ml-100k/u.item', sep='|', names=[\"movie_id\", \"movie_title\", \"release_date\", \"video release_date\", \"IMDb URL\", \"unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children's\", \"Comedy\", \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\", \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"], encoding='latin-1')\n",
    "#print (\"data_item\",data_item)\n",
    "data_item= data_item.drop(columns=['movie_title', 'video release_date','IMDb URL'])\n",
    "data_item['release_date'] = data_item['release_date'].str[-4:]\n",
    "#print (\"data_item\",data_item)\n",
    "\n",
    "\n",
    "#add popularity column to data_item panda\n",
    "\n",
    "data_item['unpopular']= data_item['movie_id'].map(lambda x: 1 if str(x) in FemaleID_str else 0)\n",
    "print(data_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c88abe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate user-item features\n",
    "\n",
    "DATA=[]\n",
    "feature_list=[]\n",
    "label_list=[]\n",
    "for user in sorted(random.sample(D.keys(), 150)):  #choose 100 users randomly\n",
    "    label_array=[]\n",
    "    for item in sorted(random.sample(item_set, 150)): #choose 100 items randomly\n",
    "        df_user= data_user.loc[data_user['user_id'] == user]\n",
    "        df_user= df_user.reset_index(drop=True)\n",
    "        df_item= data_item.loc[data_item['movie_id'] == item]\n",
    "        df_item= df_item.reset_index(drop=True)\n",
    "        feature_list.append(pd.concat([df_user,df_item], axis=1))\n",
    "        if item in D[user]:\n",
    "            label_array.append(1)  \n",
    "        else:\n",
    "            label_array.append(0)\n",
    "    label_list.append(np.array(label_array))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d076ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = pd.concat(feature_list) #change the feature list that contains multiple dataframes, to a single dataframe with single head and multiplee rows(vertical) \n",
    "feature_list= feature_list.drop(columns=['user_id', 'movie_id'])\n",
    "preprocess = make_column_transformer((StandardScaler(),['age','release_date']), \n",
    "                                     (OneHotEncoder(sparse=False), ['gender', 'job', 'unpopular']), remainder='passthrough')\n",
    "feature_list = preprocess.fit_transform(feature_list)\n",
    "feature_list= np.split(feature_list, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45da5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data based on interaction (not user)\n",
    "\n",
    "data_X = []\n",
    "data_Y = []\n",
    "test_X = []\n",
    "test_Y = []\n",
    "docID_test = []\n",
    "\n",
    "for u in range(len(label_list)):\n",
    "    all_index = list(range(len(label_list[u])))\n",
    "    train_index = set(random.sample(all_index, int(0.8* len(all_index))))\n",
    "    test_index = list(set(all_index) - train_index)\n",
    "    train_index = list(train_index)\n",
    "    data_X.append(feature_list[u][train_index])\n",
    "    data_Y.append(label_list[u][train_index])\n",
    "    test_X.append(feature_list[u][test_index])\n",
    "    test_Y.append(label_list[u][test_index])\n",
    "    docID_test.append(np.take(item_set, test_index).tolist())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#remove qid with sum_female=0 or sum_male=0\n",
    "F_rel=0\n",
    "M_rel=0\n",
    "unwanted_u=[]\n",
    "\n",
    "for u in range(len(docID_test)):\n",
    "    F_rel=0\n",
    "    M_rel=0\n",
    "    for doc in range(len(docID_test[0])):\n",
    "        if str(docID_test[u][doc]) in least_rated_movies:\n",
    "            F_rel= F_rel+ test_Y[u][doc]  \n",
    "        else:\n",
    "            M_rel= M_rel+ test_Y[u][doc]\n",
    "    if F_rel==0 or M_rel==0:\n",
    "        unwanted_u.append(u)\n",
    "\n",
    "\n",
    "test_X_ = []\n",
    "test_Y_ = []\n",
    "docID_test_=[]\n",
    "for i in range(len(test_X)):\n",
    "    if i not in unwanted_u:\n",
    "        test_X_.append(test_X[i])\n",
    "        test_Y_.append(test_Y[i])\n",
    "        docID_test_.append(docID_test[i])\n",
    "test_X= test_X_\n",
    "test_Y= test_Y_\n",
    "docID_test= docID_test_\n",
    "\n",
    "\n",
    "\n",
    "pickle.dump(docID_test, open( \"MovieLense_docID_test_25.txt\", \"wb\" ) )\n",
    "\n",
    "pkl.dump((data_X, data_Y), open(\"MovieLense_train_rank_25.pkl\", \"wb\"))\n",
    "pkl.dump((test_X, test_Y), open(\"MovieLense_test_rank_25.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bb530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "\n",
    "docID_test = pickle.load( open( \"MovieLense_docID_test_25.txt\", \"rb\" ) )\n",
    "\n",
    "with open('MovieLense_train_rank_25.pkl', 'rb') as f:\n",
    "    data_train = pkl.load(f)\n",
    "\n",
    "with open('MovieLense_test_rank_25.pkl', 'rb') as f:\n",
    "     data_test = pickle.load(f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd7b519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learn Rel-scores\n",
    "\n",
    "from YahooDataReader import YahooDataReader\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "dr = YahooDataReader(None)\n",
    "dr.data = pkl.load(open(\"MovieLense_train_rank_25.pkl\", \"rb\"))\n",
    "vdr = YahooDataReader(None)\n",
    "vdr.data = pkl.load(open(\"MovieLense_test_rank_25.pkl\",\"rb\"))                  \n",
    "model = linear_model.LinearRegression(fit_intercept=False, normalize=False)\n",
    "feats, rel = dr.data\n",
    "feats = np.array([item for sublist in feats for item in sublist])\n",
    "rel = np.array([item for sublist in rel for item in sublist])\n",
    "model.fit(feats, rel)\n",
    "feats, rel = vdr.data\n",
    "se_sum = 0\n",
    "length = 0\n",
    "predicted_rels = []\n",
    "for i, query in enumerate(feats):\n",
    "    rel_pred = model.predict(query)\n",
    "    predicted_rels.append(rel_pred)\n",
    "    se_sum += np.sum((rel_pred - rel[i])**2)\n",
    "    length += len(rel[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7681898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main Code\n",
    "\n",
    "\n",
    "#We have nothing to do with train anymore. Now we have test data consisting of 100 qid each with 25 documents.#\n",
    "#Given the docIDs for each qid, in docID_test , predicted_relScores for each docID, in predicted_rels, plus group identities, FORGE provide fair ranking\n",
    "\n",
    "\n",
    "\n",
    "docID_test_str=[[] for _ in range(len(docID_test))] #type=str\n",
    "size_female_test = []\n",
    "size_male_test=[]\n",
    "sum_rel_female=[]\n",
    "sum_rel_male= []\n",
    "sum_rel_totall=[]\n",
    "for qid in range(len(docID_test)):\n",
    "    #print (\"qid\", qid)\n",
    "    F_size= 0\n",
    "    M_size= 0\n",
    "    F_rel=0\n",
    "    M_rel=0\n",
    "    for doc in range(len(docID_test[0])):\n",
    "        docID_test_str[qid].append(str(docID_test[qid][doc]))\n",
    "        if str(docID_test[qid][doc]) in FemaleID_str:\n",
    "            F_size=F_size+1\n",
    "            F_rel= F_rel+ data_test[1][qid][doc]  # predicted_rels[qid][doc] if assume precietd rel is ground truth and data_test[1][qid][doc] O.W\n",
    "        else:\n",
    "            M_size= M_size+1\n",
    "            M_rel= M_rel+ data_test[1][qid][doc]  # predicted_rels[qid][doc] if assume precietd rel is ground truth and data_test[1][qid][doc] O.W \n",
    "    \n",
    "    size_female_test.append(F_size) #number of female docs at each query\n",
    "    size_male_test.append(M_size)\n",
    "    totall_size= len (docID_test_str[qid])\n",
    "    sum_rel_female.append(F_rel) #sum of rel score of female at each query\n",
    "    sum_rel_male.append(M_rel)\n",
    "    sum_rel_totall.append(sum_rel_female[qid]+ sum_rel_male[qid])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae8a7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_Divergence(p1,p2,q1,q2): #can use jenson divergance that is bounded between 0 and 1#\n",
    "    if p1!=0 and p2!=0:\n",
    "        J=(    (p1*np.log((2*p1)/(p1+q1)))  +  (p2*np.log((2*p2)/(p2+q2)))    +  (q1*np.log((2*q1)/(p1+q1)))  +  (q2*np.log((2*q2)/(p2+q2)))    ) / 2\n",
    "    elif p1==0:\n",
    "        J=(    (p2*np.log((2*p2)/(p2+q2)))    +  (q1*np.log((2*q1)/(p1+q1)))  +  (q2*np.log((2*q2)/(p2+q2)))    ) / 2\n",
    "    elif p2==0:\n",
    "\n",
    "        J=(   (p1*np.log((2*p1)/(p1+q1)))  +  (q1*np.log((2*q1)/(p1+q1)))  +  (q2*np.log((2*q2)/(p2+q2)))    ) / 2\n",
    "    else:\n",
    "        J=(   (q1*np.log((2*q1)/(p1+q1)))  +  (q2*np.log((2*q2)/(p2+q2)))   )/ 2 \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000989b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fairness(size_docID, \n",
    "             size_female, \n",
    "             size_male, \n",
    "             current_male_CTR, \n",
    "             sofar_male_CTR, \n",
    "             current_female_CTR, \n",
    "             sofar_female_CTR,\n",
    "             ):\n",
    "\n",
    "\n",
    "    CTR_male = sofar_male_CTR + current_male_CTR\n",
    "    CTR_female =  sofar_female_CTR + current_female_CTR\n",
    "    CTR_total = CTR_male + CTR_female\n",
    "    current_fairness= 1- KL_Divergence(CTR_male / CTR_total,\n",
    "                                       CTR_female / CTR_total,\n",
    "                                       size_male/size_docID, \n",
    "                                       size_female/size_docID\n",
    "                                       )\n",
    "    return current_fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacc0d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_and_sort(\n",
    "    docID,\n",
    "    rel_scores\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Arg list:\n",
    "    movieID: list of movie IDs. Here, list of all docID for a certain qid\n",
    "    rel_scores: dict() that maps movie_ID -> rel_score\n",
    "    \"\"\"\n",
    "    female_sorted_by_rel = []\n",
    "    male_sorted_by_rel = []\n",
    "    \n",
    "    for i in docID:    \n",
    "        if i in FemaleID_str:\n",
    "            female_sorted_by_rel.append(i)\n",
    "        else:\n",
    "            male_sorted_by_rel.append(i)\n",
    "\n",
    "    female_sorted_by_rel.sort(key = lambda x : rel_scores[x], reverse=True) \n",
    "#     print (\"female_sorted_by_rel\", female_sorted_by_rel)\n",
    "    male_sorted_by_rel.sort(key = lambda x : rel_scores[x], reverse=True)\n",
    "    #print (\"male_sorted_by_rel\",male_sorted_by_rel)\n",
    "\n",
    "    return male_sorted_by_rel, female_sorted_by_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e88a95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def interpolation_optimized(\n",
    "    qid,\n",
    "    docID,\n",
    "    rel_scores,\n",
    "    Z,\n",
    "):\n",
    "    \"\"\"\n",
    "    Arg list:\n",
    "    docID: list of docIDs for each qid in test data\n",
    "    rel_scores: dict() that maps doc_ID -> rel_score\n",
    "    Z: Z value for interpolation\n",
    "    \"\"\"\n",
    "    all_sorted_by_rel= sorted(docID, key = lambda x : rel_scores[x], reverse=True)\n",
    "#     print (\"all_sorted_by_rel\", len(all_sorted_by_rel))\n",
    "#     print('rel_scores', rel_scores)\n",
    "    S=[]\n",
    "    sofar_female_CTR=0\n",
    "    sofar_male_CTR=0\n",
    "    sofar_DCG=0\n",
    "    IDCG=0\n",
    "    \n",
    "    availablity = all_sorted_by_rel[:] #make a copy of all_sorted to avoid del make problem for IDCG\n",
    "    while len (S)< 25:\n",
    "        #print (\"S\", len(S))\n",
    "        IDCG= IDCG+ (float(2**float(rel_scores[all_sorted_by_rel[len(S)]])-1) /  math.log2(1+len(S)+1))\n",
    "        epsilon_1= 0.65\n",
    "        epsilon_plus= 1- ((len(S)+2)/100)\n",
    "        epsilon_minus= epsilon_1* (1/min( len(S)+1, 10) )\n",
    "        max_intpol_score = 0\n",
    "        max_item_data = None\n",
    "        for item in availablity:\n",
    "            DCG = sofar_DCG+ (float(2**float(rel_scores[item])-1) /  math.log2(1+len(S)+1))\n",
    "            nDCG =  float (DCG)/ IDCG\n",
    "            if item in FemaleID_str:\n",
    "                #print (\"FemaleID_str is available\")\n",
    "                current_male_CTR = 0\n",
    "                current_female_CTR = float(  (rel_scores[item]* epsilon_plus) + ( (1-rel_scores[item]) * epsilon_minus)  ) * 1/math.log2(1+len(S)+1)\n",
    "            else:\n",
    "                current_male_CTR =   float(  (rel_scores[item]* epsilon_plus) + ( (1-rel_scores[item]) * epsilon_minus)  ) * 1/math.log2(1+len(S)+1)\n",
    "                current_female_CTR = 0\n",
    "            #print (\"fairnes_component\", sum_rel_totall[qid], sum_rel_female[qid], sum_rel_male[qid], current_male_CTR, sofar_male_CTR, current_female_CTR, sofar_female_CTR)\n",
    "            fair_metric = fairness(sum_rel_totall[qid], sum_rel_female[qid], sum_rel_male[qid], current_male_CTR, sofar_male_CTR, current_female_CTR, sofar_female_CTR)\n",
    "            #print (\"fair_metric\", fair_metric)\n",
    "            intpol_score = (1-Z) * nDCG + Z * fair_metric\n",
    "            if intpol_score > max_intpol_score:\n",
    "                max_intpol_score = intpol_score\n",
    "                max_item_data = (item, current_female_CTR, current_male_CTR, DCG)\n",
    "\n",
    "\n",
    "        #print(\"max_item_data\", max_item_data)\n",
    "        S.append(max_item_data[0])\n",
    "        availablity.remove(max_item_data[0])\n",
    "        sofar_female_CTR += max_item_data[1]\n",
    "        sofar_male_CTR += max_item_data[2]\n",
    "        sofar_DCG = max_item_data[3]\n",
    "        \n",
    "    #print (\"S\", S)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed6679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_nDCG(docID, rel_scores, item_list):\n",
    "    \"\"\"\n",
    "    gives the nDCG of ranking\n",
    "    input:\n",
    "    docID: id of documents\n",
    "    rel_scores: relevant scores assuming predict = ground truth or not\n",
    "    item_list: dictionary key= docID, value= relscores\n",
    "    \"\"\"\n",
    "    sorted_docID= sorted(docID, key=lambda x:rel_scores [docID.index(x)] , reverse=True)   #a: b means a is input and will be sorted based on b. Here x= docID that will be sorted based on rel scores#\n",
    "    Denom= float(0)\n",
    "    Nom= float(0)\n",
    "    for i in range (len(item_list)):\n",
    "        temp1= D_real[str(sorted_docID[i])] #D1 if want to assume predicted rel is ground truth, D_real otherwise#\n",
    "        temp2= 2**(float (temp1))\n",
    "        Denom= Denom+(   (temp2-1)  / (math.log2(i+2))    )\n",
    "        temp3= D_real[str(item_list[i])]    #D1 if want to assume predicted rel is ground truth, D_real otherwise#\n",
    "        temp4= 2**(float (temp3))\n",
    "        Nom=Nom + (  (temp4-1)  / (math.log2(i+2))    )\n",
    "    nDCG= (float(Nom)/float(Denom))\n",
    "    return (nDCG, sorted_docID  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971d919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_divergence (qid, docID, rel_scores):\n",
    "    sofar_female_CTR=0\n",
    "    sofar_male_CTR=0\n",
    "    D_movie_list=[]\n",
    "    for i in range(len(docID)):\n",
    "        epsilon_1= 0.65\n",
    "        epsilon_plus= 1- ((i+2)/100)\n",
    "        epsilon_minus= epsilon_1* ( 1/min (i+1, 10) )\n",
    "        if docID[i] in FemaleID_str:\n",
    "            sofar_female_CTR += float(  (rel_scores[docID[i]]* epsilon_plus) + ( (1-rel_scores[docID[i]]) * epsilon_minus)  ) * 1/math.log2(i+2)\n",
    "        else:\n",
    "            sofar_male_CTR +=   float(  (rel_scores[docID[i]]* epsilon_plus) + ( (1-rel_scores[docID[i]]) * epsilon_minus)  ) * 1/math.log2(i+2)\n",
    "        \n",
    "        CTR_total= sofar_female_CTR+ sofar_male_CTR  \n",
    "        D_movie_list.append(KL_Divergence(sofar_male_CTR/ CTR_total, sofar_female_CTR/ CTR_total , sum_rel_male[qid]/sum_rel_totall[qid], sum_rel_female[qid]/sum_rel_totall[qid]))\n",
    "    return (D_movie_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb08410",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "\n",
    "interplotion_value=[1]\n",
    "for z in interplotion_value:\n",
    "    D2={} # a dictionary: key= user id, value= S/item_list\n",
    "\n",
    "    nDCG_all_q=[]\n",
    "    D_item_list_all_q=[]\n",
    "\n",
    "    #print (\"len-docid-test\", len(docID_test))\n",
    "    for qid in range(len(docID_test)):\n",
    "        nDCG=[]\n",
    "        nDiv=[]\n",
    "        #print (\"qid\", qid)\n",
    "        D1={} # a dictionary: key= movieID, value= predicted rel_scores\n",
    "        D_real= {} # a dictionary: key= movieID, value= true rel_scores\n",
    "        for i in range (len(docID_test[0])):\n",
    "            D1[docID_test_str[qid][i]]= predicted_rels[qid][i]\n",
    "            D_real[docID_test_str[qid][i]]= data_test[1][qid][i]\n",
    "        item_list  = interpolation_optimized (qid,docID_test_str[qid], D1, z)\n",
    "        for i in range(len(item_list)):\n",
    "            nDCG.append(get_nDCG(docID_test[qid], data_test[1][qid], item_list[0:i+1])[0]) #predicted_rels[qid] if assume precietd rel is ground truth, data_test[1][qid] Otherwise\n",
    "            D_item_list= get_divergence(qid, item_list[0:i+1], D_real)  #D1 if we assume predicted=true rel, and D_real o.w\n",
    "\n",
    "\n",
    "        nDCG_all_q.append (nDCG)\n",
    "        D_item_list_all_q.append(D_item_list)\n",
    "\n",
    "\n",
    "\n",
    "    avg_nDCG_at_indx_all_q= np.mean(nDCG_all_q, axis=0)\n",
    "    avg_D_item_list_at_indx_all_q= np.mean(D_item_list_all_q, axis=0)\n",
    "\n",
    "\n",
    "    print (\"avg_nDCG_at_indx_all_q\", avg_nDCG_at_indx_all_q[0])\n",
    "    print (\"avg_D_item_list_at_indx_all_q\", avg_D_item_list_at_indx_all_q[0])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
