{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code learn ranking based on fairness def of CTR, and evaluate based on fairness def of CTR with trust bias (GermanCredit data)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from YahooDataReader import YahooDataReader\n",
    "import math\n",
    "import statistics\n",
    "import itertools\n",
    "from random import seed, shuffle\n",
    "import os,sys\n",
    "import urllib.request  as urllib2\n",
    "from collections import defaultdict\n",
    "from sklearn import preprocessing\n",
    "from IPython.display import display\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "df = pd.read_csv(\"../data/german_credit_data.csv\", index_col=0)\n",
    "df = df.fillna(value=\"NA\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaleID= df.query('Sex == \"male\"').index\n",
    "FemaleID= df.query('Sex == \"female\"').index\n",
    "MaleID_str=[]\n",
    "FemaleID_str=[]\n",
    "for i in MaleID:\n",
    "    MaleID_str.append(str(i))\n",
    "for i in FemaleID:\n",
    "    FemaleID_str.append(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = make_column_transformer((StandardScaler(),['Age', 'Credit amount', 'Duration']),\n",
    "    (OneHotEncoder(sparse=False), ['Sex', 'Job', 'Housing', 'Saving accounts', 'Checking account', 'Purpose', 'Risk']))\n",
    "print (\"type\",type(df))\n",
    "mat = preprocess.fit_transform(df)\n",
    "mat[996, :]   #row 10 all columns (11th row in df)#\n",
    "\n",
    "\n",
    "X = mat[:, :-2]   \n",
    "Y = mat[:, -1]  \n",
    "num_feats = X.shape[1]\n",
    "numX = X.shape[0]\n",
    "\n",
    "datasize = 500 #number of qid in train\n",
    "cs_size = 25 #number of docs under each qid\n",
    "split_on_doc = 0.8\n",
    "testsize = 100 #number of qid in test\n",
    "ratio_relevant = 0.4\n",
    "ratios_col = Y * ratio_relevant + (1-Y)*(1-ratio_relevant)\n",
    "# print (ratios_col)\n",
    "\n",
    "# generate a candidate set of size 25 everytime for each qid\n",
    "data_X = []\n",
    "data_Y = []\n",
    "test_X = []\n",
    "test_Y = []\n",
    "group_identities_train = []\n",
    "group_identities_test = []\n",
    "print(\"Sampling between 0 and {} for train\".format(numX*split_on_doc))\n",
    "p = ratios_col[0:int(numX*split_on_doc)]\n",
    "p = p / sum(p)\n",
    "docID_train= [] #list of docID that was randomly chosen for each qid in train#\n",
    "for i in range(datasize):\n",
    "    cs_indices = np.random.choice(np.arange(0, numX*split_on_doc, dtype=int), size=cs_size, p=p) #doc index chosen for a qid#\n",
    "    docID_train.append (cs_indices.tolist())\n",
    "    cs_X = X[cs_indices] #features of chosen docs#\n",
    "    cs_Y = Y[cs_indices] #rel of chosen docs#\n",
    "    data_X.append(cs_X)\n",
    "    data_Y.append(cs_Y)\n",
    "    group_identities_train.append(cs_X[:,4]) #5th column (index=4) and all row. It is male column#\n",
    "print(\"Sampling between {} and {} for test\".format(numX*split_on_doc, numX))\n",
    "p = ratios_col[int(numX*split_on_doc):]\n",
    "p = p/sum(p)\n",
    "docID_test= []\n",
    "while len(docID_test) < testsize: #used while instead of for to make sure given \"continue\", we still have len(testsize) docs#\n",
    "    cs_indices = np.random.choice(np.arange(numX*split_on_doc, numX, dtype=int), size=cs_size, p=p)\n",
    "    #*START: added to skip the sets that has zero female or male or all female rel score 0 or all male relscore 0*#\n",
    "    group_id= X[cs_indices,4]\n",
    "    if (len(set(group_id))==1 or \n",
    "        sum([Y[item] for i, item in enumerate(cs_indices) if group_id[i]==0]) == 0 or\n",
    "        sum([Y[item] for i, item in enumerate(cs_indices) if group_id[i]==1]) == 0):\n",
    "        continue\n",
    "    #*END: added to skip the sets that has zero female or male*#\n",
    "    docID_test.append (cs_indices.tolist())\n",
    "    #print (\"docID_test\", docID_test)\n",
    "    test_X.append(X[cs_indices])\n",
    "    test_Y.append(Y[cs_indices])\n",
    "    group_identities_test.append(X[cs_indices,4])\n",
    "\n",
    "\n",
    "pickle.dump(docID_test, open( \"german_docID_test_25.txt\", \"wb\" ) )\n",
    "\n",
    "pkl.dump((data_X, data_Y), open(\"german_train_rank_25.pkl\", \"wb\"))\n",
    "pkl.dump((test_X, test_Y), open(\"german_test_rank_25.pkl\", \"wb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "\n",
    "docID_test = pickle.load( open( \"german_docID_test_25.txt\", \"rb\" ) )\n",
    "\n",
    "with open('german_train_rank_25.pkl', 'rb') as f:\n",
    "    data_train = pickle.load(f)\n",
    "\n",
    "\n",
    "#same for data_test but with size 100 instead of 500\n",
    "with open('german_test_rank_25.pkl', 'rb') as f:\n",
    "     data_test = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn rel scores\n",
    "dr = YahooDataReader(None)\n",
    "dr.data = pkl.load(open(\"german_train_rank_25.pkl\", \"rb\"))\n",
    "vdr = YahooDataReader(None)\n",
    "vdr.data = pkl.load(open(\"german_test_rank_25.pkl\",\"rb\"))                  \n",
    "model = linear_model.LinearRegression(fit_intercept=False) #, normalize=False\n",
    "feats, rel = dr.data\n",
    "feats = np.array([item for sublist in feats for item in sublist])\n",
    "rel = np.array([item for sublist in rel for item in sublist])\n",
    "model.fit(feats, rel)\n",
    "feats, rel = vdr.data\n",
    "se_sum = 0\n",
    "length = 0\n",
    "predicted_rels = []\n",
    "for i, query in enumerate(feats):\n",
    "    rel_pred = model.predict(query)\n",
    "    #print (rel_pred)\n",
    "    predicted_rels.append(rel_pred)\n",
    "    se_sum += np.sum((rel_pred - rel[i])**2)\n",
    "    length += len(rel[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fair Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "docID_test_str=[[] for _ in range(len(docID_test))] #type=str\n",
    "size_female_test = []\n",
    "size_male_test=[]\n",
    "sum_rel_female=[]\n",
    "sum_rel_male= []\n",
    "sum_rel_totall=[]\n",
    "sum_rel_female_predicted=[]\n",
    "sum_rel_male_predicted= []\n",
    "sum_rel_totall_predicted=[]\n",
    "\n",
    "\n",
    "for qid in range(len(docID_test)):\n",
    "    F_size= 0\n",
    "    M_size= 0\n",
    "    F_rel=0\n",
    "    M_rel=0\n",
    "    F_rel_predicted=0\n",
    "    M_rel_predicted=0\n",
    "    for doc in range(len(docID_test[0])):\n",
    "        docID_test_str[qid].append(str(docID_test[qid][doc]))\n",
    "        if str(docID_test[qid][doc]) in FemaleID_str:\n",
    "            F_size=F_size+1\n",
    "            F_rel= F_rel+ data_test[1][qid][int (float(docID_test_str[qid][doc]))] # used only for evaluation (ML1M)\n",
    "            F_rel_predicted= F_rel_predicted+ predicted_rels[qid][int (float(docID_test_str[qid][doc]))] #used in FORGE and LinkedIn algo (ML1M)\n",
    "            \n",
    "        else:\n",
    "            M_size= M_size+1\n",
    "            M_rel= M_rel+ data_test[1][qid][int (float(docID_test_str[qid][doc]))]\n",
    "            M_rel_predicted= M_rel_predicted+ predicted_rels[qid][int (float(docID_test_str[qid][doc]))] \n",
    "    \n",
    "    size_female_test.append(F_size) \n",
    "    size_male_test.append(M_size)\n",
    "    totall_size= len (docID_test_str[qid])\n",
    "    \n",
    "    sum_rel_female.append(F_rel) \n",
    "    sum_rel_male.append(M_rel)\n",
    "    sum_rel_totall.append(sum_rel_female[qid]+ sum_rel_male[qid])\n",
    "    \n",
    "    sum_rel_female_predicted.append(F_rel_predicted) \n",
    "    sum_rel_male_predicted.append(M_rel_predicted)\n",
    "    sum_rel_totall_predicted.append(sum_rel_female_predicted[qid]+ sum_rel_male_predicted[qid])\n",
    "\n",
    "for i in range(len(np.divide(sum_rel_female, size_female_test))):\n",
    "    if np.divide(sum_rel_female_predicted, size_female_test)[i] > np.divide(sum_rel_male_predicted, size_male_test)[i]:\n",
    "        print (\"f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_Divergence(p1,p2,q1,q2): #can use jenson divergance that is bounded between 0 and 1#\n",
    "    if p1!=0 and p2!=0:\n",
    "        J=(    (p1*np.log((2*p1)/(p1+q1)))  +  (p2*np.log((2*p2)/(p2+q2)))    +  (q1*np.log((2*q1)/(p1+q1)))  +  (q2*np.log((2*q2)/(p2+q2)))    ) / 2\n",
    "    elif p1==0:\n",
    "        J=(    (p2*np.log((2*p2)/(p2+q2)))    +  (q1*np.log((2*q1)/(p1+q1)))  +  (q2*np.log((2*q2)/(p2+q2)))    ) / 2\n",
    "    elif p2==0:\n",
    "        J=(   (p1*np.log((2*p1)/(p1+q1)))  +  (q1*np.log((2*q1)/(p1+q1)))  +  (q2*np.log((2*q2)/(p2+q2)))    ) / 2\n",
    "    else:\n",
    "        J=(   (q1*np.log((2*q1)/(p1+q1)))  +  (q2*np.log((2*q2)/(p2+q2)))   )/ 2 \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fairness(size_docID, \n",
    "             size_female, \n",
    "             size_male, \n",
    "             current_male_CTR, \n",
    "             sofar_male_CTR, \n",
    "             current_female_CTR, \n",
    "             sofar_female_CTR,\n",
    "             ):\n",
    "\n",
    "\n",
    "    CTR_male = sofar_male_CTR + current_male_CTR\n",
    "    CTR_female =  sofar_female_CTR + current_female_CTR\n",
    "    CTR_total = CTR_male + CTR_female\n",
    "    current_fairness= 1- KL_Divergence(CTR_male / CTR_total,\n",
    "                                       CTR_female / CTR_total,\n",
    "                                       size_male/size_docID, \n",
    "                                       size_female/size_docID\n",
    "                                       )\n",
    "    return current_fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_and_sort(\n",
    "    docID,\n",
    "    rel_scores\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Arg list:\n",
    "    movieID: list of movie IDs. Here, list of all docID for a certain qid\n",
    "    rel_scores: dict() that maps movie_ID -> rel_score\n",
    "    \"\"\"\n",
    "    female_sorted_by_rel = []\n",
    "    male_sorted_by_rel = []\n",
    "    \n",
    "    for i in docID:    \n",
    "        if i in FemaleID_str:\n",
    "            female_sorted_by_rel.append(i)\n",
    "        else:\n",
    "            male_sorted_by_rel.append(i)\n",
    "\n",
    "    female_sorted_by_rel.sort(key = lambda x : rel_scores[x], reverse=True) \n",
    "    male_sorted_by_rel.sort(key = lambda x : rel_scores[x], reverse=True)\n",
    "\n",
    "    return male_sorted_by_rel, female_sorted_by_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def interpolation_optimized(\n",
    "    qid,\n",
    "    docID,\n",
    "    rel_scores,\n",
    "    Z,\n",
    "):\n",
    "    \"\"\"\n",
    "    Arg list:\n",
    "    docID: list of docIDs for each qid in test data\n",
    "    rel_scores: dict() that maps doc_ID -> rel_score\n",
    "    Z: Z value for interpolation\n",
    "    \"\"\"\n",
    "    all_sorted_by_rel= sorted(docID, key = lambda x : rel_scores[x], reverse=True)\n",
    "    S=[]\n",
    "    sofar_female_CTR=0\n",
    "    sofar_male_CTR=0\n",
    "    sofar_DCG=0\n",
    "    IDCG=0\n",
    "    \n",
    "    availablity = all_sorted_by_rel[:] #make a copy of all_sorted to avoid del make problem for IDCG\n",
    "    while len (S)< 30:\n",
    "        IDCG= IDCG+ (float(2**float(rel_scores[all_sorted_by_rel[len(S)]])-1) /  math.log2(1+len(S)+1))\n",
    "        epsilon_1= 0.65\n",
    "        epsilon_plus= 1- ((len(S)+2)/100)\n",
    "        epsilon_minus= epsilon_1* (1/min( len(S)+1, 10) )\n",
    "        max_intpol_score = 0\n",
    "        max_item_data = None\n",
    "        for item in availablity:\n",
    "            DCG = sofar_DCG+ (float(2**float(rel_scores[item])-1) /  math.log2(1+len(S)+1))\n",
    "            nDCG =  float (DCG)/ IDCG\n",
    "            if item in FemaleID_str:\n",
    "                current_male_CTR = 0\n",
    "                current_female_CTR = float(  (rel_scores[item]* epsilon_plus) + ( (1-rel_scores[item]) * epsilon_minus)  ) * 1/math.log2(1+len(S)+1)\n",
    "            else:\n",
    "                current_male_CTR =   float(  (rel_scores[item]* epsilon_plus) + ( (1-rel_scores[item]) * epsilon_minus)  ) * 1/math.log2(1+len(S)+1)\n",
    "                current_female_CTR = 0\n",
    "            fair_metric = fairness(sum_rel_totall_predicted[qid], sum_rel_female_predicted[qid], sum_rel_male_predicted[qid], current_male_CTR, sofar_male_CTR, current_female_CTR, sofar_female_CTR)\n",
    "            intpol_score = (1-Z) * nDCG + Z * fair_metric\n",
    "            if intpol_score > max_intpol_score:\n",
    "                max_intpol_score = intpol_score\n",
    "                max_item_data = (item, current_female_CTR, current_male_CTR, DCG)\n",
    "\n",
    "\n",
    "\n",
    "        S.append(max_item_data[0])\n",
    "        availablity.remove(max_item_data[0])\n",
    "        sofar_female_CTR += max_item_data[1]\n",
    "        sofar_male_CTR += max_item_data[2]\n",
    "        sofar_DCG = max_item_data[3]\n",
    "        \n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_nDCG(docID, rel_scores, item_list):\n",
    "    \"\"\"\n",
    "    gives the nDCG of ranking\n",
    "    input:\n",
    "    docID: id of documents\n",
    "    rel_scores: relevant scores assuming predict = ground truth or not\n",
    "    item_list: dictionary key= docID, value= relscores\n",
    "    \"\"\"\n",
    "    sorted_docID= sorted(docID, key=lambda x:rel_scores [int(x)] , reverse=True) #for ML1M\n",
    "    #print (\"sorted_docID\", sorted_docID)\n",
    "    Denom= float(0)\n",
    "    Nom= float(0)\n",
    "    for i in range (len(item_list)):\n",
    "        temp1= D_real[str(sorted_docID[i])] #D1 if want to assume predicted rel is ground truth, D_real otherwise#\n",
    "        temp2= 2**(float (temp1))\n",
    "        Denom= Denom+(   (temp2-1)  / (math.log2(i+2))    )\n",
    "        temp3= D_real[str(item_list[i])]    #D1 if want to assume predicted rel is ground truth, D_real otherwise#\n",
    "        temp4= 2**(float (temp3))\n",
    "        Nom=Nom + (  (temp4-1)  / (math.log2(i+2))    )\n",
    "    nDCG= (float(Nom)/float(Denom))\n",
    "    return (nDCG, sorted_docID  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_divergence (qid, docID, rel_scores):\n",
    "    sofar_female_CTR=0\n",
    "    sofar_male_CTR=0\n",
    "    D_movie_list=[]\n",
    "    D_male_list=[]\n",
    "    D_female_list=[]\n",
    "    for i in range(len(docID)):\n",
    "        epsilon_1= 0.65\n",
    "        epsilon_plus= 1- ((i+2)/100)\n",
    "        epsilon_minus= epsilon_1* ( 1/min (i+1, 10) )\n",
    "        if docID[i] in FemaleID_str:\n",
    "            sofar_female_CTR += float(  (rel_scores[docID[i]]* epsilon_plus) + ( (1-rel_scores[docID[i]]) * epsilon_minus)  ) * 1/math.log2(i+2)\n",
    "        else:\n",
    "            sofar_male_CTR +=   float(  (rel_scores[docID[i]]* epsilon_plus) + ( (1-rel_scores[docID[i]]) * epsilon_minus)  ) * 1/math.log2(i+2)\n",
    "        \n",
    "        CTR_total= sofar_female_CTR+ sofar_male_CTR  \n",
    "        D_movie_list.append(KL_Divergence(sofar_male_CTR/ CTR_total, sofar_female_CTR/ CTR_total , sum_rel_male[qid]/sum_rel_totall[qid], sum_rel_female[qid]/sum_rel_totall[qid]))\n",
    "        D_male_list.append(float((sofar_male_CTR/ CTR_total)/(sum_rel_male[qid]/sum_rel_totall[qid])))\n",
    "        D_female_list.append(float((sofar_female_CTR/ CTR_total)/(sum_rel_female[qid]/sum_rel_totall[qid])))\n",
    "    return (D_movie_list, D_male_list, D_female_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_divergence_trust_DP (qid, docID, rel_scores):\n",
    "    sofar_female_CTR=0\n",
    "    sofar_male_CTR=0\n",
    "    D_movie_list=[]\n",
    "    for i in range(len(docID)):\n",
    "        epsilon_1= 0.65\n",
    "        epsilon_plus= 1- ((i+2)/100)\n",
    "        epsilon_minus= epsilon_1* ( 1/min (i+1, 10) )\n",
    "        if docID[i] in FemaleID_str:\n",
    "            sofar_female_CTR += float(  (rel_scores[docID[i]]* epsilon_plus) + ( (1-rel_scores[docID[i]]) * epsilon_minus)  ) * 1/math.log2(i+2)\n",
    "        else:\n",
    "            sofar_male_CTR +=   float(  (rel_scores[docID[i]]* epsilon_plus) + ( (1-rel_scores[docID[i]]) * epsilon_minus)  ) * 1/math.log2(i+2)\n",
    "        \n",
    "        CTR_total= sofar_female_CTR+ sofar_male_CTR  \n",
    "        D_movie_list.append(KL_Divergence(sofar_male_CTR/ CTR_total, sofar_female_CTR/ CTR_total , size_male_test[qid]/totall_size, size_female_test[qid]/totall_size))\n",
    "    return (D_movie_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_divergence_pos_DT (qid, docID, rel_scores):\n",
    "    sofar_female_exp=0\n",
    "    sofar_male_exp=0\n",
    "    D_movie_list=[]\n",
    "    for i in range(len(docID)):\n",
    "        if docID[i] in FemaleID_str:\n",
    "            sofar_female_exp +=  1/math.log2(i+2)\n",
    "        else:\n",
    "            sofar_male_exp +=  1/math.log2(i+2)\n",
    "        \n",
    "        exp_total= sofar_female_exp+ sofar_male_exp  \n",
    "        D_movie_list.append(KL_Divergence(sofar_male_exp/ exp_total, sofar_female_exp/ exp_total , sum_rel_male[qid]/sum_rel_totall[qid], sum_rel_female[qid]/sum_rel_totall[qid]))\n",
    "    return (D_movie_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_divergence_pos_DP (qid, docID, rel_scores):\n",
    "    sofar_female_exp=0\n",
    "    sofar_male_exp=0\n",
    "    D_movie_list=[]\n",
    "    for i in range(len(docID)):\n",
    "        if docID[i] in FemaleID_str:\n",
    "            sofar_female_exp +=  1/math.log2(i+2)\n",
    "        else:\n",
    "            sofar_male_exp +=  1/math.log2(i+2)\n",
    "        \n",
    "        exp_total= sofar_female_exp+ sofar_male_exp  \n",
    "        D_movie_list.append(KL_Divergence(sofar_male_exp/ exp_total, sofar_female_exp/ exp_total , size_male_test[qid]/totall_size, size_female_test[qid]/totall_size))\n",
    "    return (D_movie_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is fairness definition of joachims (difference) based on disparate treatment\n",
    "\n",
    "def get_joachims_diff (qid, docID):  #gives a vector that has conv at each rank indx. can feed both item_list and sorted_item_list#\n",
    "    \n",
    "        \n",
    "    sofar_female_expo=0\n",
    "    sofar_male_expo=0\n",
    "    sofar_indx_expo=0\n",
    "    Diff_movie_list=[]\n",
    "    for i in range(len(docID)):\n",
    "        if docID[i] in FemaleID_str:\n",
    "            sofar_female_expo= sofar_female_expo+(1/math.log2(i+2)) \n",
    "        else:\n",
    "            sofar_male_expo= sofar_male_expo + (1/math.log2(i+2))   \n",
    "        sofar_indx_expo= sofar_indx_expo+ (1/math.log2(i+2))\n",
    "        if sum_rel_male[qid]/size_male_test[qid] > sum_rel_female[qid]/size_female_test[qid]:\n",
    "            sign= 1\n",
    "        else:\n",
    "            sign=-1\n",
    "        Diff_movie_list.append(max(0, sign*diff(sofar_male_expo/ size_male_test[qid], sofar_female_expo/ size_female_test[qid] , sum_rel_male[qid]/size_male_test[qid], sum_rel_female[qid]/size_female_test[qid])))\n",
    "\n",
    "    return (Diff_movie_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CPFair_diff (qid, docID):  #gives a vector that has conv at each rank indx. can feed both item_list and sorted_item_list#\n",
    "    \n",
    "        \n",
    "    sofar_female_count=0\n",
    "    sofar_male_count=0\n",
    "    Diff_movie_list=[]\n",
    "    for i in range(len(docID)):\n",
    "        if docID[i] in FemaleID_str:\n",
    "            sofar_female_count= sofar_female_count+1 \n",
    "        else:\n",
    "            sofar_male_count= sofar_male_count + 1   \n",
    "        Diff_movie_list.append(abs(sofar_male_count- sofar_female_count))\n",
    "\n",
    "    return (Diff_movie_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_FairMetric(DocID, DivOrDiff_item_list):    #do not need it if we have new trust and CTR\n",
    "    Denom=float(0)\n",
    "    Nom=float(0)\n",
    "    for i in range (len(DocID)):\n",
    "        Denom= Denom+ (1/ (math.log2(i+2)))\n",
    "        Nom= Nom+ (1/ (math.log2(i+2)))*DivOrDiff_item_list[i]   \n",
    "    n_item_list= float(Nom)/ float(Denom)\n",
    "    return (n_item_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "\n",
    "interplotion_value=[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.91, 0.92, 0.94, 0.96, 0.98, 0.99, 1]\n",
    "for z in interplotion_value:\n",
    "    D2={} # a dictionary: key= user id, value= S/item_list\n",
    "\n",
    "    nDCG_all_q=[]\n",
    "    D_item_list_all_q=[]\n",
    "    male_Div_all_q=[]\n",
    "    female_Div_all_q=[]\n",
    "    \n",
    "    D_item_list_trust_DP_all_q=[]\n",
    "    D_item_list_pos_DT_all_q=[]\n",
    "    D_item_list_pos_DP_all_q=[]\n",
    "    joachims_diff_item_list_all_q=[]\n",
    "    CPFair_diff_item_list_all_q=[]\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    for qid in range(len(docID_test)):\n",
    "        nDCG=[]\n",
    "        nDiv=[]\n",
    "        D1={} # a dictionary: key= movieID, value= predicted rel_scores\n",
    "        D_real= {} # a dictionary: key= movieID, value= true rel_scores\n",
    "        for i in range (len(docID_test[0])):\n",
    "            #D1[docID_test_str[qid][i]]= predicted_rels[qid][i] # for German Compas Comcast and ML100K\n",
    "            #D_real[docID_test_str[qid][i]]= data_test[1][qid][i] # for German Compas Comcast and ML100K\n",
    "            \n",
    "            D1[docID_test_str[qid][i]]= predicted_rels[qid][int (float(docID_test_str[qid][i]))] # for ML1M\n",
    "            D_real[docID_test_str[qid][i]]= data_test[1][qid][int (float(docID_test_str[qid][i]))] # for ML1M\n",
    "\n",
    "        item_list  = interpolation_optimized (qid,docID_test_str[qid], D1, z)\n",
    "        for i in range(len(item_list)):\n",
    "            nDCG.append(get_nDCG(docID_test[qid], data_test[1][qid], item_list[0:i+1])[0]) #predicted_rels[qid] if assume precietd rel is ground truth, data_test[1][qid] Otherwise\n",
    "            D_item_list= get_divergence(qid, item_list[0:i+1], D_real)[0]  #D1 if we assume predicted=true rel, and D_real o.w\n",
    "            male_Div= get_divergence(qid, item_list[0:i+1], D_real)[1]\n",
    "            female_Div= get_divergence(qid, item_list[0:i+1], D_real)[2]\n",
    "            \n",
    "            D_item_list_trust_DP= get_divergence_trust_DP (qid, item_list[0:i+1], D_real)\n",
    "            D_item_list_pos_DT= get_divergence_pos_DT (qid, item_list[0:i+1], D_real)\n",
    "            D_item_list_pos_DP= get_divergence_pos_DP (qid, item_list[0:i+1], D_real)\n",
    "            joachims_diff_item_list= get_joachims_diff (qid, item_list[0:i+1])\n",
    "            CPFair_diff_item_list= get_CPFair_diff (qid, item_list[0:i+1])\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "        nDCG_all_q.append (nDCG)\n",
    "        D_item_list_all_q.append(D_item_list)\n",
    "        male_Div_all_q.append(male_Div)\n",
    "        female_Div_all_q.append(female_Div)\n",
    "        \n",
    "        D_item_list_trust_DP_all_q.append(D_item_list_trust_DP)\n",
    "        D_item_list_pos_DT_all_q.append(D_item_list_pos_DT)\n",
    "        D_item_list_pos_DP_all_q.append(D_item_list_pos_DP)\n",
    "        joachims_diff_item_list_all_q.append(joachims_diff_item_list)\n",
    "        CPFair_diff_item_list_all_q.append(CPFair_diff_item_list)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    avg_nDCG_at_indx_all_q= np.mean(nDCG_all_q, axis=0)\n",
    "    avg_D_item_list_at_indx_all_q= np.mean(D_item_list_all_q, axis=0)\n",
    "    avg_male_Div_at_indx_all_q= np.mean(male_Div_all_q, axis=0)\n",
    "    avg_female_Div_at_indx_all_q= np.mean(female_Div_all_q, axis=0)\n",
    "    \n",
    "    avg_D_item_list_trust_DP_at_indx_all_q= np.mean(D_item_list_trust_DP_all_q, axis=0)\n",
    "    avg_D_item_list_pos_DT_at_indx_all_q= np.mean(D_item_list_pos_DT_all_q, axis=0)\n",
    "    avg_D_item_list_pos_DP_at_indx_all_q= np.mean(D_item_list_pos_DP_all_q, axis=0)\n",
    "    avg_joachims_diff_item_list_at_indx_all_q= np.mean(joachims_diff_item_list_all_q, axis=0)\n",
    "    avg_CPFair_diff_item_list_at_indx_all_q= np.mean(CPFair_diff_item_list_all_q, axis=0)\n",
    "    \n",
    "\n",
    "    print (\"K=5\")\n",
    "    print (avg_nDCG_at_indx_all_q[4], end='\\t')\n",
    "    print (avg_D_item_list_at_indx_all_q[4], end='\\t')\n",
    "    print (avg_male_Div_at_indx_all_q[4], end='\\t')\n",
    "    print (avg_female_Div_at_indx_all_q[4], end='\\t')\n",
    "    print (avg_D_item_list_trust_DP_at_indx_all_q[4], end='\\t')\n",
    "    print (avg_D_item_list_pos_DT_at_indx_all_q[4], end='\\t')\n",
    "    print (avg_D_item_list_pos_DP_at_indx_all_q[4], end='\\t')\n",
    "    print (avg_joachims_diff_item_list_at_indx_all_q[4], end='\\t')\n",
    "    print (avg_CPFair_diff_item_list_at_indx_all_q[4], end='\\t')\n",
    "    print (\"********************\")\n",
    "    print (\"********************\")\n",
    "    print (\"K=10\")\n",
    "    print ( avg_nDCG_at_indx_all_q[9], end='\\t')\n",
    "    print ( avg_D_item_list_at_indx_all_q[9], end='\\t')\n",
    "    print ( avg_male_Div_at_indx_all_q[9], end='\\t')\n",
    "    print ( avg_female_Div_at_indx_all_q[9], end='\\t')\n",
    "    print (avg_D_item_list_trust_DP_at_indx_all_q[9], end='\\t')\n",
    "    print (avg_D_item_list_pos_DT_at_indx_all_q[9], end='\\t')\n",
    "    print (avg_D_item_list_pos_DP_at_indx_all_q[9], end='\\t')\n",
    "    print ( avg_joachims_diff_item_list_at_indx_all_q[9], end='\\t')\n",
    "    print ( avg_CPFair_diff_item_list_at_indx_all_q[9], end='\\t')\n",
    "    print (\"********************\")\n",
    "    print (\"********************\")\n",
    "    print (\"K=30\")\n",
    "    print ( avg_nDCG_at_indx_all_q[29], end='\\t')\n",
    "    print ( avg_D_item_list_at_indx_all_q[29], end='\\t')\n",
    "    print ( avg_male_Div_at_indx_all_q[29], end='\\t')\n",
    "    print ( avg_female_Div_at_indx_all_q[29], end='\\t')\n",
    "    print ( avg_D_item_list_trust_DP_at_indx_all_q[29], end='\\t')\n",
    "    print ( avg_D_item_list_pos_DT_at_indx_all_q[29], end='\\t')\n",
    "    print ( avg_D_item_list_pos_DP_at_indx_all_q[29], end='\\t')\n",
    "    print ( avg_joachims_diff_item_list_at_indx_all_q[29], end='\\t')\n",
    "    print ( avg_CPFair_diff_item_list_at_indx_all_q[29], end='\\t')\n",
    "    print (\"********************\")\n",
    "    print (\"********************\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
