{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code learn ranking based on fairness def of CTR, and evaluate based on fairness def of CTR with trust bias (Compas data)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from YahooDataReader import YahooDataReader\n",
    "import math\n",
    "import statistics\n",
    "import itertools\n",
    "from random import seed, shuffle\n",
    "import os,sys\n",
    "import urllib.request  as urllib2\n",
    "from collections import defaultdict\n",
    "from sklearn import preprocessing\n",
    "from IPython.display import display\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def add_intercept(x):\n",
    "\n",
    "    \"\"\" Add intercept to the data before linear classification \"\"\"\n",
    "    m,n = x.shape\n",
    "    intercept = np.ones(m).reshape(m, 1) # the constant b\n",
    "    return np.concatenate((intercept, x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_compas_data():\n",
    "\n",
    "    FEATURES_CLASSIFICATION = [\"age_cat\", \"race\", \"sex\", \"priors_count\", \"c_charge_degree\"] #features to be used for classification\n",
    "    CONT_VARIABLES = [\"priors_count\"] # continuous features, will need to be handled separately from categorical features, categorical features will be encoded using one-hot\n",
    "    CLASS_FEATURE = \"two_year_recid\" # the decision variable\n",
    "    SENSITIVE_ATTRS = [\"race\"]\n",
    "\n",
    "\n",
    "    COMPAS_INPUT_FILE = \"../data/compas.csv\"  # Comas data address\n",
    "\n",
    "    # load the data and get some stats\n",
    "    df = pd.read_csv(COMPAS_INPUT_FILE)\n",
    "    df\n",
    "    df = df.dropna(subset=[\"days_b_screening_arrest\"]) # dropping missing vals\n",
    "\n",
    "    # convert to np array\n",
    "    data = df.to_dict('list')\n",
    "    for k in data.keys():\n",
    "        data[k] = np.array(data[k])\n",
    "\n",
    "\n",
    "    \"\"\" Filtering the data \"\"\"\n",
    "\n",
    "    # These filters are the same as propublica (refer to https://github.com/propublica/compas-analysis)\n",
    "    # If the charge date of a defendants Compas scored crime was not within 30 days from when the person was arrested, we assume that because of data quality reasons, that we do not have the right offense. \n",
    "    idx = np.logical_and(data[\"days_b_screening_arrest\"]<=30, data[\"days_b_screening_arrest\"]>=-30)\n",
    "\n",
    "\n",
    "    # We coded the recidivist flag -- is_recid -- to be -1 if we could not find a compas case at all.\n",
    "    idx = np.logical_and(idx, data[\"is_recid\"] != -1)\n",
    "\n",
    "    # In a similar vein, ordinary traffic offenses -- those with a c_charge_degree of 'O' -- will not result in Jail time are removed (only two of them).\n",
    "    idx = np.logical_and(idx, data[\"c_charge_degree\"] != \"O\") # F: felony, M: misconduct\n",
    "\n",
    "    # We filtered the underlying data from Broward county to include only those rows representing people who had either recidivated in two years, or had at least two years outside of a correctional facility.\n",
    "    idx = np.logical_and(idx, data[\"score_text\"] != \"NA\")\n",
    "\n",
    "    # we will only consider blacks and whites for this analysis\n",
    "    idx = np.logical_and(idx, np.logical_or(data[\"race\"] == \"African-American\", data[\"race\"] == \"Caucasian\"))\n",
    "\n",
    "    # select the examples that satisfy this criteria\n",
    "    for k in data.keys():\n",
    "        data[k] = data[k][idx]\n",
    "\n",
    "    #display(data)\n",
    "\n",
    "    \"\"\" Feature normalization and one hot encoding \"\"\"\n",
    "\n",
    "    # convert class label 0 to -1\n",
    "    y = data[CLASS_FEATURE]\n",
    "    #y[y==0] = -1\n",
    "\n",
    "\n",
    "\n",
    "    print (\"\\nNumber of people recidivating within two years\")\n",
    "    print (pd.Series(y).value_counts())\n",
    "    print (\"\\n\")\n",
    "\n",
    "\n",
    "    X = np.array([]).reshape(len(y), 0) # empty array with num rows same as num examples, will hstack the features to it\n",
    "    x_control = defaultdict(list)\n",
    "\n",
    "    feature_names = []\n",
    "    for attr in FEATURES_CLASSIFICATION:\n",
    "        print (\"attr\", attr)\n",
    "        vals = data[attr]\n",
    "        if attr in CONT_VARIABLES:\n",
    "            vals = [float(v) for v in vals]\n",
    "            vals = preprocessing.scale(vals) # 0 mean and 1 variance  \n",
    "            vals = np.reshape(vals, (len(y), -1)) # convert from 1-d arr to a 2-d arr with one col\n",
    "\n",
    "        else: # for binary categorical variables, the label binarizer uses just one var instead of two\n",
    "            lb = preprocessing.LabelBinarizer()\n",
    "            lb.fit(vals)\n",
    "            vals = lb.transform(vals)\n",
    "    \n",
    "        # add to sensitive features dict\n",
    "        if attr in SENSITIVE_ATTRS:\n",
    "            print (\"True\")\n",
    "            x_control[attr] = vals\n",
    "\n",
    "\n",
    "        # add to learnable features\n",
    "        X = np.hstack((X, vals))\n",
    "\n",
    "        if attr in CONT_VARIABLES: # continuous feature, just append the name\n",
    "            feature_names.append(attr)\n",
    "        else: # categorical features\n",
    "            if vals.shape[1] == 1: # binary features that passed through lib binarizer\n",
    "                feature_names.append(attr + \"_\" + str(lb.classes_[1]))\n",
    "            else:\n",
    "                for k in lb.classes_: # non-binary categorical features, need to add the names for each cat\n",
    "                    feature_names.append(attr + \"_\" + str(k))\n",
    "\n",
    "\n",
    "    # convert the sensitive feature to 1-d array\n",
    "    x_control = dict(x_control)\n",
    "    for k in x_control.keys():\n",
    "        assert(x_control[k].shape[1] == 1) # make sure that the sensitive feature is binary after one hot encoding\n",
    "        x_control[k] = np.array(x_control[k]).flatten()\n",
    "    print (\"x_control\", x_control)\n",
    "    # sys.exit(1)\n",
    "\n",
    "    #\"\"\"permute the date randomly\"\"\"\n",
    "    #perm = list(range(0,X.shape[0])\n",
    "    #shuffle(perm)\n",
    "    #X = X[perm]\n",
    "    #y = y[perm]\n",
    "    #for k in x_control.keys():\n",
    "    #x_control[k] = x_control[k][perm]\n",
    "\n",
    "\n",
    "    X = add_intercept(X)\n",
    "\n",
    "    feature_names = [\"intercept\"] + feature_names\n",
    "    assert(len(feature_names) == X.shape[1])\n",
    "    print (\"Features we will be using for classification are:\", feature_names, \"\\n\")\n",
    "\n",
    "    # wrtie data in csv file\n",
    "\n",
    "    #A = pd.DataFrame(list(x_control.items()),columns=['index','race'])\n",
    "    #A.to_csv('compas_A.csv', sep='\\t') \n",
    "    y = pd.DataFrame(data=y,columns=['two_year_recid'])\n",
    "    y.to_csv('compas_Y.csv', sep='\\t') \n",
    "    X1 = pd.DataFrame(data=X[0:,0:],columns=feature_names) #X[0,1:] #index=X[0:,0]\n",
    "    #print (\"X1B\", X1.keys())\n",
    "    A = X1.race_Caucasian\n",
    "    #print (\"A\", A)\n",
    "    X1.drop(['race_Caucasian'], axis=1) #in place-- does not work.So X1 is unchanged\n",
    "    print (\"X1\", X1.keys())\n",
    "    #X = pd.DataFrame(list(X.items()),columns=feature_names)\n",
    "    X1.to_csv('compas_X.csv', sep='\\t')\n",
    "    A.to_csv('compas_A.csv', sep='\\t')\n",
    "    data = pd.concat([A,X1],axis = 1).values #race_caucasian column is added to ll data. So this feature appears twice, once at index=0 and also at index=5. Here, we consider cocuasians to be bottom rank in criminal search\n",
    "    #print (\"data\", data)\n",
    "    return data, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sample_record(orig_data, orig_label):\n",
    "\n",
    "    #data, to_protect, label = load_compas_data() #read_arrhythmia(shuffle=True, dropmissing=True)\n",
    "\n",
    "    data = orig_data\n",
    "    orig_label = np.array(orig_label)\n",
    "    label = orig_label\n",
    "\n",
    "    data = pd.DataFrame(data)\n",
    "    label = pd.DataFrame(label)\n",
    "    display(data)\n",
    "\n",
    "\n",
    "    Y = np.array(label)\n",
    "    Y = np.squeeze(Y)\n",
    "\n",
    "    #data = pd.concat([to_protect,data],axis = 1).values\n",
    "\n",
    "    X = np.array(data)\n",
    "\n",
    "    num_feats = X.shape[1]\n",
    "    numX = X.shape[0]\n",
    "    #print(\"num_feat: \", num_feats)\n",
    "    #print(\"Y: \", Y)\n",
    "\n",
    "    datasize = 500\n",
    "    cs_size = 25\n",
    "    split_on_doc = 0.8\n",
    "    testsize = 100\n",
    "    ratio_relevant = 0.4\n",
    "    ratios_col = Y * ratio_relevant + (1-Y)*(1-ratio_relevant)\n",
    "\n",
    "    # generate a candidate set of size 10 everytime\n",
    "    data_X = []\n",
    "    data_Y = []\n",
    "    test_X = []\n",
    "    test_Y = []\n",
    "    group_identities_train = []\n",
    "    group_identities_test = []\n",
    "    print(\"Sampling between 0 and {} for train\".format(numX*split_on_doc))\n",
    "    p = ratios_col[0:int(numX*split_on_doc)]\n",
    "    p = p / sum(p)\n",
    "    for i in range(datasize):\n",
    "        cs_indices = np.random.choice(np.arange(0, int(numX*split_on_doc), dtype=int), size=cs_size, p=p)\n",
    "        cs_X = X[cs_indices]\n",
    "        cs_Y = Y[cs_indices]\n",
    "        data_X.append(cs_X)\n",
    "        data_Y.append(cs_Y)\n",
    "        group_identities_train.append(cs_X[:,0]) #index=0 shows caucasian= whites\n",
    "    print(\"Sampling between {} and {} for test\".format(int(numX*split_on_doc), numX))\n",
    "    p = ratios_col[int(numX*split_on_doc):]\n",
    "    p = p/sum(p)\n",
    "    docID_test= []\n",
    "    #for i in range(testsize): \n",
    "    while len(docID_test) < testsize: #used while instead of for to make sure given \"continue\", we still have len(testsize) qid#\n",
    "        cs_indices = np.random.choice(np.arange(numX*split_on_doc, numX, dtype=int), size=cs_size, p=p)\n",
    "        print (\"cs_indices\",cs_indices)\n",
    "        #*START: added to skip the sets that has zero female or male or all female rel score 0 or all male relscore 0*#\n",
    "        group_id= X[cs_indices,0]\n",
    "        print (\"group_id\", group_id)\n",
    "        if (len(set(group_id))==1 or \n",
    "            sum([Y[item] for i, item in enumerate(cs_indices) if group_id[i]==0]) == 0 or\n",
    "            sum([Y[item] for i, item in enumerate(cs_indices) if group_id[i]==1]) == 0):\n",
    "            #print (\"continue\")\n",
    "            continue\n",
    "        #*END: added to skip the sets that has zero female or male*#\n",
    "        docID_test.append (cs_indices.tolist())\n",
    "        print (\"docID_test\", docID_test)\n",
    "        test_X.append(X[cs_indices])\n",
    "        test_Y.append(Y[cs_indices])\n",
    "        group_identities_test.append(X[cs_indices,0])\n",
    "\n",
    "\n",
    "    return data_X, data_Y, test_X, test_Y, docID_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = load_compas_data()\n",
    "data_X, data_Y, test_X, test_Y, docID_test= make_sample_record(data, label)\n",
    "pkl.dump((data_X, data_Y), open(\"compas_train_rank_25.pkl\", \"wb\"))\n",
    "pkl.dump((test_X, test_Y), open(\"compas_test_rank_25.pkl\", \"wb\"))\n",
    "pickle.dump(docID_test, open( \"compas_docID_test_25.txt\", \"wb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(data)\n",
    "MaleID= data_df[data_df[0]==1].index\n",
    "FemaleID= data_df[data_df[0]==0].index\n",
    "MaleID_str=[]\n",
    "FemaleID_str=[]\n",
    "for i in MaleID:\n",
    "    MaleID_str.append(str(i))\n",
    "for i in FemaleID:\n",
    "    FemaleID_str.append(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "docID_test = pickle.load( open( \"compas_docID_test_25.txt\", \"rb\" ) )\n",
    "\n",
    "with open('compas_train_rank_25.pkl', 'rb') as f:\n",
    "    data_train = pickle.load(f)\n",
    "\n",
    "with open('compas_test_rank_25.pkl', 'rb') as f:\n",
    "     data_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn rel scores\n",
    "dr = YahooDataReader(None)\n",
    "dr.data = pkl.load(open(\"compas_train_rank_25.pkl\", \"rb\"))\n",
    "vdr = YahooDataReader(None)\n",
    "vdr.data = pkl.load(open(\"compas_test_rank_25.pkl\",\"rb\"))                  \n",
    "model = linear_model.LinearRegression(fit_intercept=False) #, normalize=False\n",
    "feats, rel = dr.data\n",
    "feats = np.array([item for sublist in feats for item in sublist])\n",
    "rel = np.array([item for sublist in rel for item in sublist])\n",
    "model.fit(feats, rel)\n",
    "# predictions on validation\n",
    "feats, rel = vdr.data\n",
    "se_sum = 0\n",
    "length = 0\n",
    "predicted_rels = []\n",
    "for i, query in enumerate(feats):\n",
    "    rel_pred = model.predict(query)    \n",
    "    predicted_rels.append(rel_pred)\n",
    "    se_sum += np.sum((rel_pred - rel[i])**2)\n",
    "    length += len(rel[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fair Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "docID_test_str=[[] for _ in range(len(docID_test))] #type=str\n",
    "size_female_test = []\n",
    "size_male_test=[]\n",
    "sum_rel_female=[]\n",
    "sum_rel_male= []\n",
    "sum_rel_totall=[]\n",
    "sum_rel_female_predicted=[]\n",
    "sum_rel_male_predicted= []\n",
    "sum_rel_totall_predicted=[]\n",
    "\n",
    "\n",
    "for qid in range(len(docID_test)):\n",
    "    F_size= 0\n",
    "    M_size= 0\n",
    "    F_rel=0\n",
    "    M_rel=0\n",
    "    F_rel_predicted=0\n",
    "    M_rel_predicted=0\n",
    "    for doc in range(len(docID_test[0])):\n",
    "        docID_test_str[qid].append(str(docID_test[qid][doc]))\n",
    "        if str(docID_test[qid][doc]) in FemaleID_str:\n",
    "            F_size=F_size+1\n",
    "            F_rel= F_rel+ data_test[1][qid][int (float(docID_test_str[qid][doc]))] # used only for evaluation (ML1M)\n",
    "            F_rel_predicted= F_rel_predicted+ predicted_rels[qid][int (float(docID_test_str[qid][doc]))] #used in FORGE and LinkedIn algo (ML1M)\n",
    "            \n",
    "        else:\n",
    "            M_size= M_size+1\n",
    "            M_rel= M_rel+ data_test[1][qid][int (float(docID_test_str[qid][doc]))]\n",
    "            M_rel_predicted= M_rel_predicted+ predicted_rels[qid][int (float(docID_test_str[qid][doc]))] \n",
    "    \n",
    "    size_female_test.append(F_size) \n",
    "    size_male_test.append(M_size)\n",
    "    totall_size= len (docID_test_str[qid])\n",
    "    \n",
    "    sum_rel_female.append(F_rel) \n",
    "    sum_rel_male.append(M_rel)\n",
    "    sum_rel_totall.append(sum_rel_female[qid]+ sum_rel_male[qid])\n",
    "    \n",
    "    sum_rel_female_predicted.append(F_rel_predicted) \n",
    "    sum_rel_male_predicted.append(M_rel_predicted)\n",
    "    sum_rel_totall_predicted.append(sum_rel_female_predicted[qid]+ sum_rel_male_predicted[qid])\n",
    "\n",
    "for i in range(len(np.divide(sum_rel_female, size_female_test))):\n",
    "    if np.divide(sum_rel_female_predicted, size_female_test)[i] > np.divide(sum_rel_male_predicted, size_male_test)[i]:\n",
    "        print (\"f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_Divergence(p1,p2,q1,q2): #can use jenson divergance that is bounded between 0 and 1#\n",
    "    if p1!=0 and p2!=0:\n",
    "        J=(    (p1*np.log((2*p1)/(p1+q1)))  +  (p2*np.log((2*p2)/(p2+q2)))    +  (q1*np.log((2*q1)/(p1+q1)))  +  (q2*np.log((2*q2)/(p2+q2)))    ) / 2\n",
    "    elif p1==0:\n",
    "        J=(    (p2*np.log((2*p2)/(p2+q2)))    +  (q1*np.log((2*q1)/(p1+q1)))  +  (q2*np.log((2*q2)/(p2+q2)))    ) / 2\n",
    "    elif p2==0:\n",
    "        J=(   (p1*np.log((2*p1)/(p1+q1)))  +  (q1*np.log((2*q1)/(p1+q1)))  +  (q2*np.log((2*q2)/(p2+q2)))    ) / 2\n",
    "    else:\n",
    "        J=(   (q1*np.log((2*q1)/(p1+q1)))  +  (q2*np.log((2*q2)/(p2+q2)))   )/ 2 \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fairness(size_docID, \n",
    "             size_female, \n",
    "             size_male, \n",
    "             current_male_CTR, \n",
    "             sofar_male_CTR, \n",
    "             current_female_CTR, \n",
    "             sofar_female_CTR,\n",
    "             ):\n",
    "\n",
    "\n",
    "    CTR_male = sofar_male_CTR + current_male_CTR\n",
    "    CTR_female =  sofar_female_CTR + current_female_CTR\n",
    "    CTR_total = CTR_male + CTR_female\n",
    "    current_fairness= 1- KL_Divergence(CTR_male / CTR_total,\n",
    "                                       CTR_female / CTR_total,\n",
    "                                       size_male/size_docID, \n",
    "                                       size_female/size_docID\n",
    "                                       )\n",
    "    return current_fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_and_sort(\n",
    "    docID,\n",
    "    rel_scores\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Arg list:\n",
    "    movieID: list of movie IDs. Here, list of all docID for a certain qid\n",
    "    rel_scores: dict() that maps movie_ID -> rel_score\n",
    "    \"\"\"\n",
    "    female_sorted_by_rel = []\n",
    "    male_sorted_by_rel = []\n",
    "    \n",
    "    for i in docID:    \n",
    "        if i in FemaleID_str:\n",
    "            female_sorted_by_rel.append(i)\n",
    "        else:\n",
    "            male_sorted_by_rel.append(i)\n",
    "\n",
    "    female_sorted_by_rel.sort(key = lambda x : rel_scores[x], reverse=True) \n",
    "    male_sorted_by_rel.sort(key = lambda x : rel_scores[x], reverse=True)\n",
    "\n",
    "    return male_sorted_by_rel, female_sorted_by_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def interpolation_optimized(\n",
    "    qid,\n",
    "    docID,\n",
    "    rel_scores,\n",
    "    Z,\n",
    "):\n",
    "    \"\"\"\n",
    "    Arg list:\n",
    "    docID: list of docIDs for each qid in test data\n",
    "    rel_scores: dict() that maps doc_ID -> rel_score\n",
    "    Z: Z value for interpolation\n",
    "    \"\"\"\n",
    "    all_sorted_by_rel= sorted(docID, key = lambda x : rel_scores[x], reverse=True)\n",
    "    S=[]\n",
    "    sofar_female_CTR=0\n",
    "    sofar_male_CTR=0\n",
    "    sofar_DCG=0\n",
    "    IDCG=0\n",
    "    \n",
    "    availablity = all_sorted_by_rel[:] #make a copy of all_sorted to avoid del make problem for IDCG\n",
    "    while len (S)< 30:\n",
    "        IDCG= IDCG+ (float(2**float(rel_scores[all_sorted_by_rel[len(S)]])-1) /  math.log2(1+len(S)+1))\n",
    "        epsilon_1= 0.65\n",
    "        epsilon_plus= 1- ((len(S)+2)/100)\n",
    "        epsilon_minus= epsilon_1* (1/min( len(S)+1, 10) )\n",
    "        max_intpol_score = 0\n",
    "        max_item_data = None\n",
    "        for item in availablity:\n",
    "            DCG = sofar_DCG+ (float(2**float(rel_scores[item])-1) /  math.log2(1+len(S)+1))\n",
    "            nDCG =  float (DCG)/ IDCG\n",
    "            if item in FemaleID_str:\n",
    "                current_male_CTR = 0\n",
    "                current_female_CTR = float(  (rel_scores[item]* epsilon_plus) + ( (1-rel_scores[item]) * epsilon_minus)  ) * 1/math.log2(1+len(S)+1)\n",
    "            else:\n",
    "                current_male_CTR =   float(  (rel_scores[item]* epsilon_plus) + ( (1-rel_scores[item]) * epsilon_minus)  ) * 1/math.log2(1+len(S)+1)\n",
    "                current_female_CTR = 0\n",
    "            fair_metric = fairness(sum_rel_totall_predicted[qid], sum_rel_female_predicted[qid], sum_rel_male_predicted[qid], current_male_CTR, sofar_male_CTR, current_female_CTR, sofar_female_CTR)\n",
    "            intpol_score = (1-Z) * nDCG + Z * fair_metric\n",
    "            if intpol_score > max_intpol_score:\n",
    "                max_intpol_score = intpol_score\n",
    "                max_item_data = (item, current_female_CTR, current_male_CTR, DCG)\n",
    "\n",
    "\n",
    "\n",
    "        S.append(max_item_data[0])\n",
    "        availablity.remove(max_item_data[0])\n",
    "        sofar_female_CTR += max_item_data[1]\n",
    "        sofar_male_CTR += max_item_data[2]\n",
    "        sofar_DCG = max_item_data[3]\n",
    "        \n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_nDCG(docID, rel_scores, item_list):\n",
    "    \"\"\"\n",
    "    gives the nDCG of ranking\n",
    "    input:\n",
    "    docID: id of documents\n",
    "    rel_scores: relevant scores assuming predict = ground truth or not\n",
    "    item_list: dictionary key= docID, value= relscores\n",
    "    \"\"\"\n",
    "    sorted_docID= sorted(docID, key=lambda x:rel_scores [int(x)] , reverse=True) #for ML1M\n",
    "    #print (\"sorted_docID\", sorted_docID)\n",
    "    Denom= float(0)\n",
    "    Nom= float(0)\n",
    "    for i in range (len(item_list)):\n",
    "        temp1= D_real[str(sorted_docID[i])] #D1 if want to assume predicted rel is ground truth, D_real otherwise#\n",
    "        temp2= 2**(float (temp1))\n",
    "        Denom= Denom+(   (temp2-1)  / (math.log2(i+2))    )\n",
    "        temp3= D_real[str(item_list[i])]    #D1 if want to assume predicted rel is ground truth, D_real otherwise#\n",
    "        temp4= 2**(float (temp3))\n",
    "        Nom=Nom + (  (temp4-1)  / (math.log2(i+2))    )\n",
    "    nDCG= (float(Nom)/float(Denom))\n",
    "    return (nDCG, sorted_docID  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_divergence (qid, docID, rel_scores):\n",
    "    sofar_female_CTR=0\n",
    "    sofar_male_CTR=0\n",
    "    D_movie_list=[]\n",
    "    D_male_list=[]\n",
    "    D_female_list=[]\n",
    "    for i in range(len(docID)):\n",
    "        epsilon_1= 0.65\n",
    "        epsilon_plus= 1- ((i+2)/100)\n",
    "        epsilon_minus= epsilon_1* ( 1/min (i+1, 10) )\n",
    "        if docID[i] in FemaleID_str:\n",
    "            sofar_female_CTR += float(  (rel_scores[docID[i]]* epsilon_plus) + ( (1-rel_scores[docID[i]]) * epsilon_minus)  ) * 1/math.log2(i+2)\n",
    "        else:\n",
    "            sofar_male_CTR +=   float(  (rel_scores[docID[i]]* epsilon_plus) + ( (1-rel_scores[docID[i]]) * epsilon_minus)  ) * 1/math.log2(i+2)\n",
    "        \n",
    "        CTR_total= sofar_female_CTR+ sofar_male_CTR  \n",
    "        D_movie_list.append(KL_Divergence(sofar_male_CTR/ CTR_total, sofar_female_CTR/ CTR_total , sum_rel_male[qid]/sum_rel_totall[qid], sum_rel_female[qid]/sum_rel_totall[qid]))\n",
    "        D_male_list.append(float((sofar_male_CTR/ CTR_total)/(sum_rel_male[qid]/sum_rel_totall[qid])))\n",
    "        D_female_list.append(float((sofar_female_CTR/ CTR_total)/(sum_rel_female[qid]/sum_rel_totall[qid])))\n",
    "    return (D_movie_list, D_male_list, D_female_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_divergence_trust_DP (qid, docID, rel_scores):\n",
    "    sofar_female_CTR=0\n",
    "    sofar_male_CTR=0\n",
    "    D_movie_list=[]\n",
    "    for i in range(len(docID)):\n",
    "        epsilon_1= 0.65\n",
    "        epsilon_plus= 1- ((i+2)/100)\n",
    "        epsilon_minus= epsilon_1* ( 1/min (i+1, 10) )\n",
    "        if docID[i] in FemaleID_str:\n",
    "            sofar_female_CTR += float(  (rel_scores[docID[i]]* epsilon_plus) + ( (1-rel_scores[docID[i]]) * epsilon_minus)  ) * 1/math.log2(i+2)\n",
    "        else:\n",
    "            sofar_male_CTR +=   float(  (rel_scores[docID[i]]* epsilon_plus) + ( (1-rel_scores[docID[i]]) * epsilon_minus)  ) * 1/math.log2(i+2)\n",
    "        \n",
    "        CTR_total= sofar_female_CTR+ sofar_male_CTR  \n",
    "        D_movie_list.append(KL_Divergence(sofar_male_CTR/ CTR_total, sofar_female_CTR/ CTR_total , size_male_test[qid]/totall_size, size_female_test[qid]/totall_size))\n",
    "    return (D_movie_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_divergence_pos_DT (qid, docID, rel_scores):\n",
    "    sofar_female_exp=0\n",
    "    sofar_male_exp=0\n",
    "    D_movie_list=[]\n",
    "    for i in range(len(docID)):\n",
    "        if docID[i] in FemaleID_str:\n",
    "            sofar_female_exp +=  1/math.log2(i+2)\n",
    "        else:\n",
    "            sofar_male_exp +=  1/math.log2(i+2)\n",
    "        \n",
    "        exp_total= sofar_female_exp+ sofar_male_exp  \n",
    "        D_movie_list.append(KL_Divergence(sofar_male_exp/ exp_total, sofar_female_exp/ exp_total , sum_rel_male[qid]/sum_rel_totall[qid], sum_rel_female[qid]/sum_rel_totall[qid]))\n",
    "    return (D_movie_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_divergence_pos_DP (qid, docID, rel_scores):\n",
    "    sofar_female_exp=0\n",
    "    sofar_male_exp=0\n",
    "    D_movie_list=[]\n",
    "    for i in range(len(docID)):\n",
    "        if docID[i] in FemaleID_str:\n",
    "            sofar_female_exp +=  1/math.log2(i+2)\n",
    "        else:\n",
    "            sofar_male_exp +=  1/math.log2(i+2)\n",
    "        \n",
    "        exp_total= sofar_female_exp+ sofar_male_exp  \n",
    "        D_movie_list.append(KL_Divergence(sofar_male_exp/ exp_total, sofar_female_exp/ exp_total , size_male_test[qid]/totall_size, size_female_test[qid]/totall_size))\n",
    "    return (D_movie_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is fairness definition of joachims (difference) based on disparate treatment\n",
    "\n",
    "def get_joachims_diff (qid, docID):  #gives a vector that has conv at each rank indx. can feed both item_list and sorted_item_list#\n",
    "    \n",
    "        \n",
    "    sofar_female_expo=0\n",
    "    sofar_male_expo=0\n",
    "    sofar_indx_expo=0\n",
    "    Diff_movie_list=[]\n",
    "    for i in range(len(docID)):\n",
    "        if docID[i] in FemaleID_str:\n",
    "            sofar_female_expo= sofar_female_expo+(1/math.log2(i+2)) \n",
    "        else:\n",
    "            sofar_male_expo= sofar_male_expo + (1/math.log2(i+2))   \n",
    "        sofar_indx_expo= sofar_indx_expo+ (1/math.log2(i+2))\n",
    "        if sum_rel_male[qid]/size_male_test[qid] > sum_rel_female[qid]/size_female_test[qid]:\n",
    "            sign= 1\n",
    "        else:\n",
    "            sign=-1\n",
    "        Diff_movie_list.append(max(0, sign*diff(sofar_male_expo/ size_male_test[qid], sofar_female_expo/ size_female_test[qid] , sum_rel_male[qid]/size_male_test[qid], sum_rel_female[qid]/size_female_test[qid])))\n",
    "\n",
    "    return (Diff_movie_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CPFair_diff (qid, docID):  #gives a vector that has conv at each rank indx. can feed both item_list and sorted_item_list#\n",
    "    \n",
    "        \n",
    "    sofar_female_count=0\n",
    "    sofar_male_count=0\n",
    "    Diff_movie_list=[]\n",
    "    for i in range(len(docID)):\n",
    "        if docID[i] in FemaleID_str:\n",
    "            sofar_female_count= sofar_female_count+1 \n",
    "        else:\n",
    "            sofar_male_count= sofar_male_count + 1   \n",
    "        Diff_movie_list.append(abs(sofar_male_count- sofar_female_count))\n",
    "\n",
    "    return (Diff_movie_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_FairMetric(DocID, DivOrDiff_item_list):    #do not need it if we have new trust and CTR\n",
    "    Denom=float(0)\n",
    "    Nom=float(0)\n",
    "    for i in range (len(DocID)):\n",
    "        Denom= Denom+ (1/ (math.log2(i+2)))\n",
    "        Nom= Nom+ (1/ (math.log2(i+2)))*DivOrDiff_item_list[i]   \n",
    "    n_item_list= float(Nom)/ float(Denom)\n",
    "    return (n_item_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "\n",
    "interplotion_value=[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.91, 0.92, 0.94, 0.96, 0.98, 0.99, 1]\n",
    "for z in interplotion_value:\n",
    "    D2={} # a dictionary: key= user id, value= S/item_list\n",
    "\n",
    "    nDCG_all_q=[]\n",
    "    D_item_list_all_q=[]\n",
    "    male_Div_all_q=[]\n",
    "    female_Div_all_q=[]\n",
    "    \n",
    "    D_item_list_trust_DP_all_q=[]\n",
    "    D_item_list_pos_DT_all_q=[]\n",
    "    D_item_list_pos_DP_all_q=[]\n",
    "    joachims_diff_item_list_all_q=[]\n",
    "    CPFair_diff_item_list_all_q=[]\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    for qid in range(len(docID_test)):\n",
    "        nDCG=[]\n",
    "        nDiv=[]\n",
    "        D1={} # a dictionary: key= movieID, value= predicted rel_scores\n",
    "        D_real= {} # a dictionary: key= movieID, value= true rel_scores\n",
    "        for i in range (len(docID_test[0])):\n",
    "            #D1[docID_test_str[qid][i]]= predicted_rels[qid][i] # for German Compas Comcast and ML100K\n",
    "            #D_real[docID_test_str[qid][i]]= data_test[1][qid][i] # for German Compas Comcast and ML100K\n",
    "            \n",
    "            D1[docID_test_str[qid][i]]= predicted_rels[qid][int (float(docID_test_str[qid][i]))] # for ML1M\n",
    "            D_real[docID_test_str[qid][i]]= data_test[1][qid][int (float(docID_test_str[qid][i]))] # for ML1M\n",
    "\n",
    "        item_list  = interpolation_optimized (qid,docID_test_str[qid], D1, z)\n",
    "        for i in range(len(item_list)):\n",
    "            nDCG.append(get_nDCG(docID_test[qid], data_test[1][qid], item_list[0:i+1])[0]) #predicted_rels[qid] if assume precietd rel is ground truth, data_test[1][qid] Otherwise\n",
    "            D_item_list= get_divergence(qid, item_list[0:i+1], D_real)[0]  #D1 if we assume predicted=true rel, and D_real o.w\n",
    "            male_Div= get_divergence(qid, item_list[0:i+1], D_real)[1]\n",
    "            female_Div= get_divergence(qid, item_list[0:i+1], D_real)[2]\n",
    "            \n",
    "            D_item_list_trust_DP= get_divergence_trust_DP (qid, item_list[0:i+1], D_real)\n",
    "            D_item_list_pos_DT= get_divergence_pos_DT (qid, item_list[0:i+1], D_real)\n",
    "            D_item_list_pos_DP= get_divergence_pos_DP (qid, item_list[0:i+1], D_real)\n",
    "            joachims_diff_item_list= get_joachims_diff (qid, item_list[0:i+1])\n",
    "            CPFair_diff_item_list= get_CPFair_diff (qid, item_list[0:i+1])\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "        nDCG_all_q.append (nDCG)\n",
    "        D_item_list_all_q.append(D_item_list)\n",
    "        male_Div_all_q.append(male_Div)\n",
    "        female_Div_all_q.append(female_Div)\n",
    "        \n",
    "        D_item_list_trust_DP_all_q.append(D_item_list_trust_DP)\n",
    "        D_item_list_pos_DT_all_q.append(D_item_list_pos_DT)\n",
    "        D_item_list_pos_DP_all_q.append(D_item_list_pos_DP)\n",
    "        joachims_diff_item_list_all_q.append(joachims_diff_item_list)\n",
    "        CPFair_diff_item_list_all_q.append(CPFair_diff_item_list)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    avg_nDCG_at_indx_all_q= np.mean(nDCG_all_q, axis=0)\n",
    "    avg_D_item_list_at_indx_all_q= np.mean(D_item_list_all_q, axis=0)\n",
    "    avg_male_Div_at_indx_all_q= np.mean(male_Div_all_q, axis=0)\n",
    "    avg_female_Div_at_indx_all_q= np.mean(female_Div_all_q, axis=0)\n",
    "    \n",
    "    avg_D_item_list_trust_DP_at_indx_all_q= np.mean(D_item_list_trust_DP_all_q, axis=0)\n",
    "    avg_D_item_list_pos_DT_at_indx_all_q= np.mean(D_item_list_pos_DT_all_q, axis=0)\n",
    "    avg_D_item_list_pos_DP_at_indx_all_q= np.mean(D_item_list_pos_DP_all_q, axis=0)\n",
    "    avg_joachims_diff_item_list_at_indx_all_q= np.mean(joachims_diff_item_list_all_q, axis=0)\n",
    "    avg_CPFair_diff_item_list_at_indx_all_q= np.mean(CPFair_diff_item_list_all_q, axis=0)\n",
    "    \n",
    "\n",
    "    print (\"K=5\")\n",
    "    print (avg_nDCG_at_indx_all_q[4], end='\\t')\n",
    "    print (avg_D_item_list_at_indx_all_q[4], end='\\t')\n",
    "    print (avg_male_Div_at_indx_all_q[4], end='\\t')\n",
    "    print (avg_female_Div_at_indx_all_q[4], end='\\t')\n",
    "    print (avg_D_item_list_trust_DP_at_indx_all_q[4], end='\\t')\n",
    "    print (avg_D_item_list_pos_DT_at_indx_all_q[4], end='\\t')\n",
    "    print (avg_D_item_list_pos_DP_at_indx_all_q[4], end='\\t')\n",
    "    print (avg_joachims_diff_item_list_at_indx_all_q[4], end='\\t')\n",
    "    print (avg_CPFair_diff_item_list_at_indx_all_q[4], end='\\t')\n",
    "    print (\"********************\")\n",
    "    print (\"********************\")\n",
    "    print (\"K=10\")\n",
    "    print ( avg_nDCG_at_indx_all_q[9], end='\\t')\n",
    "    print ( avg_D_item_list_at_indx_all_q[9], end='\\t')\n",
    "    print ( avg_male_Div_at_indx_all_q[9], end='\\t')\n",
    "    print ( avg_female_Div_at_indx_all_q[9], end='\\t')\n",
    "    print (avg_D_item_list_trust_DP_at_indx_all_q[9], end='\\t')\n",
    "    print (avg_D_item_list_pos_DT_at_indx_all_q[9], end='\\t')\n",
    "    print (avg_D_item_list_pos_DP_at_indx_all_q[9], end='\\t')\n",
    "    print ( avg_joachims_diff_item_list_at_indx_all_q[9], end='\\t')\n",
    "    print ( avg_CPFair_diff_item_list_at_indx_all_q[9], end='\\t')\n",
    "    print (\"********************\")\n",
    "    print (\"********************\")\n",
    "    print (\"K=30\")\n",
    "    print ( avg_nDCG_at_indx_all_q[29], end='\\t')\n",
    "    print ( avg_D_item_list_at_indx_all_q[29], end='\\t')\n",
    "    print ( avg_male_Div_at_indx_all_q[29], end='\\t')\n",
    "    print ( avg_female_Div_at_indx_all_q[29], end='\\t')\n",
    "    print ( avg_D_item_list_trust_DP_at_indx_all_q[29], end='\\t')\n",
    "    print ( avg_D_item_list_pos_DT_at_indx_all_q[29], end='\\t')\n",
    "    print ( avg_D_item_list_pos_DP_at_indx_all_q[29], end='\\t')\n",
    "    print ( avg_joachims_diff_item_list_at_indx_all_q[29], end='\\t')\n",
    "    print ( avg_CPFair_diff_item_list_at_indx_all_q[29], end='\\t')\n",
    "    print (\"********************\")\n",
    "    print (\"********************\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
